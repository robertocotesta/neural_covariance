{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/robertocotesta/neural_covariance.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyiLMwRglaC0",
        "outputId": "a7c4746e-8539-43fe-a26e-b96646b0a409"
      },
      "id": "WyiLMwRglaC0",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'neural_covariance'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 20 (delta 2), reused 8 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (20/20), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a704ab3e",
      "metadata": {
        "id": "a704ab3e"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2322d480",
      "metadata": {
        "id": "2322d480"
      },
      "source": [
        "## Data wrangling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bb3215ec",
      "metadata": {
        "id": "bb3215ec"
      },
      "outputs": [],
      "source": [
        "param_list = ['Mc', 'eta', 'DL', 'tc', 'phic', 'iota', 'ra', 'dec', 'psi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "34b4d5b6",
      "metadata": {
        "id": "34b4d5b6"
      },
      "outputs": [],
      "source": [
        "def recreate_symmetric_matrix(size_X,X_flatten):\n",
        "    X = np.zeros((size_X,size_X))\n",
        "    X[np.triu_indices(X.shape[0], k = 0)] = X_flatten\n",
        "    X = X + X.T - np.diag(np.diag(X))\n",
        "    return X\n",
        "\n",
        "def flatten_symmetric_matrix(X):\n",
        "    return X[np.triu_indices(X.shape[0], k = 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1e6d1943",
      "metadata": {
        "id": "1e6d1943"
      },
      "outputs": [],
      "source": [
        "with open('/content/neural_covariance/Data/input.pkl','rb') as f:\n",
        "    input_dataset = pickle.load(f)\n",
        "with open('/content/neural_covariance/Data/output.pkl','rb') as f:\n",
        "    output_dataset = pickle.load(f)    \n",
        "with open('/content/neural_covariance/Data/SNRs.pkl','rb') as f:\n",
        "    SNR_dataset = pickle.load(f)      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "af09a99c",
      "metadata": {
        "id": "af09a99c"
      },
      "outputs": [],
      "source": [
        "input_df = pd.DataFrame.from_dict(input_dataset, orient='index',columns=param_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "247edd6a",
      "metadata": {
        "id": "247edd6a"
      },
      "outputs": [],
      "source": [
        "# Each matrix is symmetric, hence I only extract and flatten its triangular upper part\n",
        "output_df = pd.DataFrame(data=[flatten_symmetric_matrix(output_dataset[i]) for i in output_dataset.keys()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "054e4499",
      "metadata": {
        "id": "054e4499"
      },
      "outputs": [],
      "source": [
        "# Load SNR for interpolation\n",
        "SNR_df = pd.DataFrame(data=SNR_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "942753db",
      "metadata": {
        "id": "942753db"
      },
      "outputs": [],
      "source": [
        "sc_Input = StandardScaler()\n",
        "sc_Output = StandardScaler()\n",
        "input_df = input_df[['Mc', 'eta', 'DL', 'iota', 'ra', 'dec']]\n",
        "# Scaling input\n",
        "scaled_input_df = sc_Input.fit_transform(input_df)\n",
        "# Scaling output\n",
        "scaled_output_df = sc_Output.fit_transform(output_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cd3d14ac",
      "metadata": {
        "id": "cd3d14ac"
      },
      "outputs": [],
      "source": [
        "# Split test, train, CV for Fisher\n",
        "# X_train, X_test, y_train, y_test = train_test_split(scaled_input_df,output_df.values,test_size=0.4,random_state=0)\n",
        "# X_CV, X_test, y_CV, y_test = train_test_split(X_test,y_test,test_size=0.5,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "9be3283c",
      "metadata": {
        "id": "9be3283c"
      },
      "outputs": [],
      "source": [
        "# Split test, train, CV for SNR\n",
        "X_train, X_test, y_train, y_test = train_test_split(scaled_input_df,SNR_df.values,test_size=0.4,random_state=0)\n",
        "X_CV, X_test, y_CV, y_test = train_test_split(X_test,y_test,test_size=0.5,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i_max = 2000\n",
        "# X_train, y_train = X_train[:i_max], y_train[:i_max]"
      ],
      "metadata": {
        "id": "MSWey9Pz4LBW"
      },
      "id": "MSWey9Pz4LBW",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6936d511",
      "metadata": {
        "id": "6936d511"
      },
      "source": [
        "## Build interpolant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "fe13090f",
      "metadata": {
        "id": "fe13090f"
      },
      "outputs": [],
      "source": [
        "# Definition of the device for training\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# General settings for the training\n",
        "epochs = 100000\n",
        "lr = 0.001\n",
        "batch_size  = y_train.shape[0]\n",
        "input_layer_dim = X_train.shape[1]\n",
        "output_layer_dim = y_train.shape[1]"
      ],
      "metadata": {
        "id": "Qxt8qXDLCSiu"
      },
      "id": "Qxt8qXDLCSiu",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "15851cb6",
      "metadata": {
        "id": "15851cb6"
      },
      "outputs": [],
      "source": [
        "# Definition of the neural network\n",
        "class interpolant(nn.Module):\n",
        "    def __init__(self,dim_input,dim_output):\n",
        "        super().__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(dim_input, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, dim_output),\n",
        "        )\n",
        "        \n",
        "    def forward(self,X):\n",
        "        return self.linear_relu_stack(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "45eea3f0",
      "metadata": {
        "id": "45eea3f0"
      },
      "outputs": [],
      "source": [
        "# Definition of dataset for interpolation\n",
        "class DatasetInterpolation(Dataset):\n",
        "    def __init__(self,X_values,y_values):\n",
        "        self.X_values = torch.from_numpy(X_values).float()\n",
        "        self.y_values = torch.from_numpy(y_values).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y_values)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X_values[idx], self.y_values[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "a57675d8",
      "metadata": {
        "id": "a57675d8"
      },
      "outputs": [],
      "source": [
        "model = interpolant(input_layer_dim,output_layer_dim).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "31f1876a",
      "metadata": {
        "id": "31f1876a"
      },
      "outputs": [],
      "source": [
        "training_data = DatasetInterpolation(X_train,y_train)\n",
        "test_data = DatasetInterpolation(X_CV,y_CV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "eed7d3ae",
      "metadata": {
        "id": "eed7d3ae"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True,pin_memory=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True,pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "7dc8480c",
      "metadata": {
        "id": "7dc8480c"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:.2E}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    print(f\"Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "a9742ab3",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a9742ab3",
        "outputId": "b5f57e6d-47e6-4e21-f300-eb07c6337af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 5.06E+05  [    0/ 6917]\n",
            "Avg loss: 554533.618750 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 4.83E+05  [    0/ 6917]\n",
            "Avg loss: 556300.956250 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 5.60E+05  [    0/ 6917]\n",
            "Avg loss: 541977.037500 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 4.85E+05  [    0/ 6917]\n",
            "Avg loss: 538679.643750 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 5.42E+05  [    0/ 6917]\n",
            "Avg loss: 505675.068750 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 5.30E+05  [    0/ 6917]\n",
            "Avg loss: 460634.200000 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 4.58E+05  [    0/ 6917]\n",
            "Avg loss: 402642.681250 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 3.95E+05  [    0/ 6917]\n",
            "Avg loss: 312048.681250 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 2.15E+05  [    0/ 6917]\n",
            "Avg loss: 254895.150000 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 2.65E+05  [    0/ 6917]\n",
            "Avg loss: 233109.834375 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 2.53E+05  [    0/ 6917]\n",
            "Avg loss: 219517.040625 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 2.69E+05  [    0/ 6917]\n",
            "Avg loss: 203235.253125 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 1.42E+05  [    0/ 6917]\n",
            "Avg loss: 197471.456250 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 2.04E+05  [    0/ 6917]\n",
            "Avg loss: 189367.775000 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 1.79E+05  [    0/ 6917]\n",
            "Avg loss: 181009.950000 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 1.61E+05  [    0/ 6917]\n",
            "Avg loss: 170675.031250 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 1.25E+05  [    0/ 6917]\n",
            "Avg loss: 158826.221875 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 1.60E+05  [    0/ 6917]\n",
            "Avg loss: 150363.423437 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 1.34E+05  [    0/ 6917]\n",
            "Avg loss: 141933.700000 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 1.12E+05  [    0/ 6917]\n",
            "Avg loss: 133713.675000 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 1.37E+05  [    0/ 6917]\n",
            "Avg loss: 128156.070312 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 1.01E+05  [    0/ 6917]\n",
            "Avg loss: 114243.532812 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 1.20E+05  [    0/ 6917]\n",
            "Avg loss: 107518.343750 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 1.23E+05  [    0/ 6917]\n",
            "Avg loss: 101341.559375 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 1.07E+05  [    0/ 6917]\n",
            "Avg loss: 93995.875000 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 9.65E+04  [    0/ 6917]\n",
            "Avg loss: 87929.057813 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 6.91E+04  [    0/ 6917]\n",
            "Avg loss: 80135.776563 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 6.61E+04  [    0/ 6917]\n",
            "Avg loss: 73072.167969 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 7.39E+04  [    0/ 6917]\n",
            "Avg loss: 69643.891406 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 6.20E+04  [    0/ 6917]\n",
            "Avg loss: 64321.539844 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 7.09E+04  [    0/ 6917]\n",
            "Avg loss: 59628.085156 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 6.35E+04  [    0/ 6917]\n",
            "Avg loss: 53536.825000 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 5.26E+04  [    0/ 6917]\n",
            "Avg loss: 52074.700000 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 4.15E+04  [    0/ 6917]\n",
            "Avg loss: 47664.057813 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 4.05E+04  [    0/ 6917]\n",
            "Avg loss: 42430.096094 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 2.78E+04  [    0/ 6917]\n",
            "Avg loss: 39737.311719 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 3.57E+04  [    0/ 6917]\n",
            "Avg loss: 36760.840625 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 3.31E+04  [    0/ 6917]\n",
            "Avg loss: 35102.548438 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 2.89E+04  [    0/ 6917]\n",
            "Avg loss: 32713.843359 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 3.27E+04  [    0/ 6917]\n",
            "Avg loss: 30626.314453 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 2.83E+04  [    0/ 6917]\n",
            "Avg loss: 28804.857422 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 2.46E+04  [    0/ 6917]\n",
            "Avg loss: 26675.951562 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 2.64E+04  [    0/ 6917]\n",
            "Avg loss: 26199.392188 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 2.12E+04  [    0/ 6917]\n",
            "Avg loss: 24234.722266 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 1.74E+04  [    0/ 6917]\n",
            "Avg loss: 23558.025000 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 2.25E+04  [    0/ 6917]\n",
            "Avg loss: 22511.342969 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 1.60E+04  [    0/ 6917]\n",
            "Avg loss: 21540.766797 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 1.68E+04  [    0/ 6917]\n",
            "Avg loss: 20700.139062 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 1.58E+04  [    0/ 6917]\n",
            "Avg loss: 20216.915625 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 2.01E+04  [    0/ 6917]\n",
            "Avg loss: 19918.014844 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 1.83E+04  [    0/ 6917]\n",
            "Avg loss: 18806.438672 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 1.87E+04  [    0/ 6917]\n",
            "Avg loss: 18216.023438 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 1.78E+04  [    0/ 6917]\n",
            "Avg loss: 17265.429883 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 1.31E+04  [    0/ 6917]\n",
            "Avg loss: 16758.229883 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 1.41E+04  [    0/ 6917]\n",
            "Avg loss: 16197.490039 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 1.42E+04  [    0/ 6917]\n",
            "Avg loss: 15231.715234 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 1.48E+04  [    0/ 6917]\n",
            "Avg loss: 14807.868945 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 1.67E+04  [    0/ 6917]\n",
            "Avg loss: 14471.384961 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 1.29E+04  [    0/ 6917]\n",
            "Avg loss: 14395.122266 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 1.11E+04  [    0/ 6917]\n",
            "Avg loss: 13665.393750 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 1.30E+04  [    0/ 6917]\n",
            "Avg loss: 12999.225586 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 1.08E+04  [    0/ 6917]\n",
            "Avg loss: 12863.247656 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 9.87E+03  [    0/ 6917]\n",
            "Avg loss: 12037.701367 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 1.06E+04  [    0/ 6917]\n",
            "Avg loss: 11963.312695 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 1.10E+04  [    0/ 6917]\n",
            "Avg loss: 11611.984766 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 9.26E+03  [    0/ 6917]\n",
            "Avg loss: 11364.176172 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 8.57E+03  [    0/ 6917]\n",
            "Avg loss: 10770.340039 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 9.69E+03  [    0/ 6917]\n",
            "Avg loss: 10567.180859 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 9.68E+03  [    0/ 6917]\n",
            "Avg loss: 10489.850977 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 9.36E+03  [    0/ 6917]\n",
            "Avg loss: 10142.484180 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 9.18E+03  [    0/ 6917]\n",
            "Avg loss: 9726.021875 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 1.00E+04  [    0/ 6917]\n",
            "Avg loss: 9436.020703 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 7.55E+03  [    0/ 6917]\n",
            "Avg loss: 9437.470215 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 1.02E+04  [    0/ 6917]\n",
            "Avg loss: 8926.165234 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 8.86E+03  [    0/ 6917]\n",
            "Avg loss: 8658.957520 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 7.30E+03  [    0/ 6917]\n",
            "Avg loss: 8529.884961 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 7.34E+03  [    0/ 6917]\n",
            "Avg loss: 8561.376660 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 6.72E+03  [    0/ 6917]\n",
            "Avg loss: 8037.723633 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 8.69E+03  [    0/ 6917]\n",
            "Avg loss: 7957.492676 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 8.90E+03  [    0/ 6917]\n",
            "Avg loss: 8032.591602 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 7.87E+03  [    0/ 6917]\n",
            "Avg loss: 7647.882324 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 8.85E+03  [    0/ 6917]\n",
            "Avg loss: 7451.768652 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 7.30E+03  [    0/ 6917]\n",
            "Avg loss: 7232.345020 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 7.31E+03  [    0/ 6917]\n",
            "Avg loss: 7133.735352 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 9.45E+03  [    0/ 6917]\n",
            "Avg loss: 6788.702930 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 6.83E+03  [    0/ 6917]\n",
            "Avg loss: 6777.956250 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 6.01E+03  [    0/ 6917]\n",
            "Avg loss: 6410.001270 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 6.80E+03  [    0/ 6917]\n",
            "Avg loss: 6583.703418 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 5.12E+03  [    0/ 6917]\n",
            "Avg loss: 6249.193945 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 5.48E+03  [    0/ 6917]\n",
            "Avg loss: 6374.354199 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 5.18E+03  [    0/ 6917]\n",
            "Avg loss: 5994.939746 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 4.65E+03  [    0/ 6917]\n",
            "Avg loss: 5892.407324 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 5.48E+03  [    0/ 6917]\n",
            "Avg loss: 5934.085742 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 3.31E+03  [    0/ 6917]\n",
            "Avg loss: 5842.652051 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 6.59E+03  [    0/ 6917]\n",
            "Avg loss: 5659.199023 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 5.27E+03  [    0/ 6917]\n",
            "Avg loss: 5636.397266 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 4.69E+03  [    0/ 6917]\n",
            "Avg loss: 5438.278809 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 6.14E+03  [    0/ 6917]\n",
            "Avg loss: 5421.095850 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 4.57E+03  [    0/ 6917]\n",
            "Avg loss: 5256.350391 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 3.89E+03  [    0/ 6917]\n",
            "Avg loss: 5212.503613 \n",
            "\n",
            "Epoch 101\n",
            "-------------------------------\n",
            "loss: 5.56E+03  [    0/ 6917]\n",
            "Avg loss: 5206.410352 \n",
            "\n",
            "Epoch 102\n",
            "-------------------------------\n",
            "loss: 5.32E+03  [    0/ 6917]\n",
            "Avg loss: 5044.040918 \n",
            "\n",
            "Epoch 103\n",
            "-------------------------------\n",
            "loss: 5.44E+03  [    0/ 6917]\n",
            "Avg loss: 4981.987012 \n",
            "\n",
            "Epoch 104\n",
            "-------------------------------\n",
            "loss: 4.76E+03  [    0/ 6917]\n",
            "Avg loss: 4752.807910 \n",
            "\n",
            "Epoch 105\n",
            "-------------------------------\n",
            "loss: 3.76E+03  [    0/ 6917]\n",
            "Avg loss: 4791.064551 \n",
            "\n",
            "Epoch 106\n",
            "-------------------------------\n",
            "loss: 5.02E+03  [    0/ 6917]\n",
            "Avg loss: 4688.573047 \n",
            "\n",
            "Epoch 107\n",
            "-------------------------------\n",
            "loss: 3.76E+03  [    0/ 6917]\n",
            "Avg loss: 4542.520996 \n",
            "\n",
            "Epoch 108\n",
            "-------------------------------\n",
            "loss: 3.55E+03  [    0/ 6917]\n",
            "Avg loss: 4599.637891 \n",
            "\n",
            "Epoch 109\n",
            "-------------------------------\n",
            "loss: 3.71E+03  [    0/ 6917]\n",
            "Avg loss: 4590.564990 \n",
            "\n",
            "Epoch 110\n",
            "-------------------------------\n",
            "loss: 4.00E+03  [    0/ 6917]\n",
            "Avg loss: 4551.013037 \n",
            "\n",
            "Epoch 111\n",
            "-------------------------------\n",
            "loss: 4.72E+03  [    0/ 6917]\n",
            "Avg loss: 4532.436475 \n",
            "\n",
            "Epoch 112\n",
            "-------------------------------\n",
            "loss: 3.68E+03  [    0/ 6917]\n",
            "Avg loss: 4334.194238 \n",
            "\n",
            "Epoch 113\n",
            "-------------------------------\n",
            "loss: 4.30E+03  [    0/ 6917]\n",
            "Avg loss: 4182.242920 \n",
            "\n",
            "Epoch 114\n",
            "-------------------------------\n",
            "loss: 3.85E+03  [    0/ 6917]\n",
            "Avg loss: 4175.108887 \n",
            "\n",
            "Epoch 115\n",
            "-------------------------------\n",
            "loss: 4.52E+03  [    0/ 6917]\n",
            "Avg loss: 4251.758496 \n",
            "\n",
            "Epoch 116\n",
            "-------------------------------\n",
            "loss: 3.43E+03  [    0/ 6917]\n",
            "Avg loss: 4313.415381 \n",
            "\n",
            "Epoch 117\n",
            "-------------------------------\n",
            "loss: 3.73E+03  [    0/ 6917]\n",
            "Avg loss: 4130.450000 \n",
            "\n",
            "Epoch 118\n",
            "-------------------------------\n",
            "loss: 3.54E+03  [    0/ 6917]\n",
            "Avg loss: 4106.190332 \n",
            "\n",
            "Epoch 119\n",
            "-------------------------------\n",
            "loss: 2.87E+03  [    0/ 6917]\n",
            "Avg loss: 3953.176123 \n",
            "\n",
            "Epoch 120\n",
            "-------------------------------\n",
            "loss: 3.77E+03  [    0/ 6917]\n",
            "Avg loss: 3920.603809 \n",
            "\n",
            "Epoch 121\n",
            "-------------------------------\n",
            "loss: 3.93E+03  [    0/ 6917]\n",
            "Avg loss: 4093.144971 \n",
            "\n",
            "Epoch 122\n",
            "-------------------------------\n",
            "loss: 3.15E+03  [    0/ 6917]\n",
            "Avg loss: 3905.624805 \n",
            "\n",
            "Epoch 123\n",
            "-------------------------------\n",
            "loss: 3.96E+03  [    0/ 6917]\n",
            "Avg loss: 3910.157129 \n",
            "\n",
            "Epoch 124\n",
            "-------------------------------\n",
            "loss: 5.15E+03  [    0/ 6917]\n",
            "Avg loss: 3916.707471 \n",
            "\n",
            "Epoch 125\n",
            "-------------------------------\n",
            "loss: 4.03E+03  [    0/ 6917]\n",
            "Avg loss: 3824.671484 \n",
            "\n",
            "Epoch 126\n",
            "-------------------------------\n",
            "loss: 4.50E+03  [    0/ 6917]\n",
            "Avg loss: 3984.437695 \n",
            "\n",
            "Epoch 127\n",
            "-------------------------------\n",
            "loss: 3.68E+03  [    0/ 6917]\n",
            "Avg loss: 3801.880078 \n",
            "\n",
            "Epoch 128\n",
            "-------------------------------\n",
            "loss: 3.76E+03  [    0/ 6917]\n",
            "Avg loss: 3799.162451 \n",
            "\n",
            "Epoch 129\n",
            "-------------------------------\n",
            "loss: 3.26E+03  [    0/ 6917]\n",
            "Avg loss: 3567.405957 \n",
            "\n",
            "Epoch 130\n",
            "-------------------------------\n",
            "loss: 3.32E+03  [    0/ 6917]\n",
            "Avg loss: 3724.149902 \n",
            "\n",
            "Epoch 131\n",
            "-------------------------------\n",
            "loss: 3.37E+03  [    0/ 6917]\n",
            "Avg loss: 3455.041846 \n",
            "\n",
            "Epoch 132\n",
            "-------------------------------\n",
            "loss: 3.11E+03  [    0/ 6917]\n",
            "Avg loss: 3525.672852 \n",
            "\n",
            "Epoch 133\n",
            "-------------------------------\n",
            "loss: 2.65E+03  [    0/ 6917]\n",
            "Avg loss: 3444.062842 \n",
            "\n",
            "Epoch 134\n",
            "-------------------------------\n",
            "loss: 2.74E+03  [    0/ 6917]\n",
            "Avg loss: 3511.658740 \n",
            "\n",
            "Epoch 135\n",
            "-------------------------------\n",
            "loss: 2.76E+03  [    0/ 6917]\n",
            "Avg loss: 3665.724658 \n",
            "\n",
            "Epoch 136\n",
            "-------------------------------\n",
            "loss: 2.72E+03  [    0/ 6917]\n",
            "Avg loss: 3448.950244 \n",
            "\n",
            "Epoch 137\n",
            "-------------------------------\n",
            "loss: 3.06E+03  [    0/ 6917]\n",
            "Avg loss: 3351.623145 \n",
            "\n",
            "Epoch 138\n",
            "-------------------------------\n",
            "loss: 2.86E+03  [    0/ 6917]\n",
            "Avg loss: 3522.477637 \n",
            "\n",
            "Epoch 139\n",
            "-------------------------------\n",
            "loss: 3.08E+03  [    0/ 6917]\n",
            "Avg loss: 3300.076953 \n",
            "\n",
            "Epoch 140\n",
            "-------------------------------\n",
            "loss: 2.79E+03  [    0/ 6917]\n",
            "Avg loss: 3280.213477 \n",
            "\n",
            "Epoch 141\n",
            "-------------------------------\n",
            "loss: 2.59E+03  [    0/ 6917]\n",
            "Avg loss: 3337.282764 \n",
            "\n",
            "Epoch 142\n",
            "-------------------------------\n",
            "loss: 2.49E+03  [    0/ 6917]\n",
            "Avg loss: 3418.607275 \n",
            "\n",
            "Epoch 143\n",
            "-------------------------------\n",
            "loss: 2.42E+03  [    0/ 6917]\n",
            "Avg loss: 3192.732373 \n",
            "\n",
            "Epoch 144\n",
            "-------------------------------\n",
            "loss: 2.32E+03  [    0/ 6917]\n",
            "Avg loss: 3166.135791 \n",
            "\n",
            "Epoch 145\n",
            "-------------------------------\n",
            "loss: 2.24E+03  [    0/ 6917]\n",
            "Avg loss: 3374.606396 \n",
            "\n",
            "Epoch 146\n",
            "-------------------------------\n",
            "loss: 3.28E+03  [    0/ 6917]\n",
            "Avg loss: 3217.664160 \n",
            "\n",
            "Epoch 147\n",
            "-------------------------------\n",
            "loss: 2.61E+03  [    0/ 6917]\n",
            "Avg loss: 3150.885693 \n",
            "\n",
            "Epoch 148\n",
            "-------------------------------\n",
            "loss: 2.22E+03  [    0/ 6917]\n",
            "Avg loss: 3323.302295 \n",
            "\n",
            "Epoch 149\n",
            "-------------------------------\n",
            "loss: 2.54E+03  [    0/ 6917]\n",
            "Avg loss: 3086.323438 \n",
            "\n",
            "Epoch 150\n",
            "-------------------------------\n",
            "loss: 2.79E+03  [    0/ 6917]\n",
            "Avg loss: 3256.566943 \n",
            "\n",
            "Epoch 151\n",
            "-------------------------------\n",
            "loss: 2.69E+03  [    0/ 6917]\n",
            "Avg loss: 3011.696338 \n",
            "\n",
            "Epoch 152\n",
            "-------------------------------\n",
            "loss: 3.01E+03  [    0/ 6917]\n",
            "Avg loss: 3203.279248 \n",
            "\n",
            "Epoch 153\n",
            "-------------------------------\n",
            "loss: 1.76E+03  [    0/ 6917]\n",
            "Avg loss: 3016.975391 \n",
            "\n",
            "Epoch 154\n",
            "-------------------------------\n",
            "loss: 2.83E+03  [    0/ 6917]\n",
            "Avg loss: 3051.293115 \n",
            "\n",
            "Epoch 155\n",
            "-------------------------------\n",
            "loss: 1.89E+03  [    0/ 6917]\n",
            "Avg loss: 3148.386182 \n",
            "\n",
            "Epoch 156\n",
            "-------------------------------\n",
            "loss: 2.69E+03  [    0/ 6917]\n",
            "Avg loss: 2974.990186 \n",
            "\n",
            "Epoch 157\n",
            "-------------------------------\n",
            "loss: 2.31E+03  [    0/ 6917]\n",
            "Avg loss: 2919.378320 \n",
            "\n",
            "Epoch 158\n",
            "-------------------------------\n",
            "loss: 2.94E+03  [    0/ 6917]\n",
            "Avg loss: 3027.979492 \n",
            "\n",
            "Epoch 159\n",
            "-------------------------------\n",
            "loss: 2.52E+03  [    0/ 6917]\n",
            "Avg loss: 2870.382080 \n",
            "\n",
            "Epoch 160\n",
            "-------------------------------\n",
            "loss: 3.18E+03  [    0/ 6917]\n",
            "Avg loss: 2875.159131 \n",
            "\n",
            "Epoch 161\n",
            "-------------------------------\n",
            "loss: 1.99E+03  [    0/ 6917]\n",
            "Avg loss: 2960.927686 \n",
            "\n",
            "Epoch 162\n",
            "-------------------------------\n",
            "loss: 2.30E+03  [    0/ 6917]\n",
            "Avg loss: 2918.686035 \n",
            "\n",
            "Epoch 163\n",
            "-------------------------------\n",
            "loss: 2.61E+03  [    0/ 6917]\n",
            "Avg loss: 2790.993945 \n",
            "\n",
            "Epoch 164\n",
            "-------------------------------\n",
            "loss: 2.02E+03  [    0/ 6917]\n",
            "Avg loss: 2842.778125 \n",
            "\n",
            "Epoch 165\n",
            "-------------------------------\n",
            "loss: 2.37E+03  [    0/ 6917]\n",
            "Avg loss: 3188.865332 \n",
            "\n",
            "Epoch 166\n",
            "-------------------------------\n",
            "loss: 2.23E+03  [    0/ 6917]\n",
            "Avg loss: 2918.563135 \n",
            "\n",
            "Epoch 167\n",
            "-------------------------------\n",
            "loss: 2.17E+03  [    0/ 6917]\n",
            "Avg loss: 2851.656885 \n",
            "\n",
            "Epoch 168\n",
            "-------------------------------\n",
            "loss: 2.25E+03  [    0/ 6917]\n",
            "Avg loss: 2784.853027 \n",
            "\n",
            "Epoch 169\n",
            "-------------------------------\n",
            "loss: 1.90E+03  [    0/ 6917]\n",
            "Avg loss: 2790.852930 \n",
            "\n",
            "Epoch 170\n",
            "-------------------------------\n",
            "loss: 2.27E+03  [    0/ 6917]\n",
            "Avg loss: 2733.634424 \n",
            "\n",
            "Epoch 171\n",
            "-------------------------------\n",
            "loss: 2.54E+03  [    0/ 6917]\n",
            "Avg loss: 2685.967139 \n",
            "\n",
            "Epoch 172\n",
            "-------------------------------\n",
            "loss: 3.02E+03  [    0/ 6917]\n",
            "Avg loss: 2743.174902 \n",
            "\n",
            "Epoch 173\n",
            "-------------------------------\n",
            "loss: 2.26E+03  [    0/ 6917]\n",
            "Avg loss: 2637.863379 \n",
            "\n",
            "Epoch 174\n",
            "-------------------------------\n",
            "loss: 2.76E+03  [    0/ 6917]\n",
            "Avg loss: 2732.464404 \n",
            "\n",
            "Epoch 175\n",
            "-------------------------------\n",
            "loss: 1.99E+03  [    0/ 6917]\n",
            "Avg loss: 2733.619580 \n",
            "\n",
            "Epoch 176\n",
            "-------------------------------\n",
            "loss: 2.41E+03  [    0/ 6917]\n",
            "Avg loss: 2653.128613 \n",
            "\n",
            "Epoch 177\n",
            "-------------------------------\n",
            "loss: 2.85E+03  [    0/ 6917]\n",
            "Avg loss: 2680.605273 \n",
            "\n",
            "Epoch 178\n",
            "-------------------------------\n",
            "loss: 2.05E+03  [    0/ 6917]\n",
            "Avg loss: 2545.610303 \n",
            "\n",
            "Epoch 179\n",
            "-------------------------------\n",
            "loss: 2.19E+03  [    0/ 6917]\n",
            "Avg loss: 2558.641748 \n",
            "\n",
            "Epoch 180\n",
            "-------------------------------\n",
            "loss: 2.29E+03  [    0/ 6917]\n",
            "Avg loss: 2631.167114 \n",
            "\n",
            "Epoch 181\n",
            "-------------------------------\n",
            "loss: 2.78E+03  [    0/ 6917]\n",
            "Avg loss: 2681.988379 \n",
            "\n",
            "Epoch 182\n",
            "-------------------------------\n",
            "loss: 1.76E+03  [    0/ 6917]\n",
            "Avg loss: 2731.706836 \n",
            "\n",
            "Epoch 183\n",
            "-------------------------------\n",
            "loss: 2.88E+03  [    0/ 6917]\n",
            "Avg loss: 2691.711523 \n",
            "\n",
            "Epoch 184\n",
            "-------------------------------\n",
            "loss: 1.85E+03  [    0/ 6917]\n",
            "Avg loss: 2749.357373 \n",
            "\n",
            "Epoch 185\n",
            "-------------------------------\n",
            "loss: 2.04E+03  [    0/ 6917]\n",
            "Avg loss: 2473.160474 \n",
            "\n",
            "Epoch 186\n",
            "-------------------------------\n",
            "loss: 1.73E+03  [    0/ 6917]\n",
            "Avg loss: 2509.533301 \n",
            "\n",
            "Epoch 187\n",
            "-------------------------------\n",
            "loss: 1.98E+03  [    0/ 6917]\n",
            "Avg loss: 2514.595898 \n",
            "\n",
            "Epoch 188\n",
            "-------------------------------\n",
            "loss: 2.31E+03  [    0/ 6917]\n",
            "Avg loss: 2431.243286 \n",
            "\n",
            "Epoch 189\n",
            "-------------------------------\n",
            "loss: 1.86E+03  [    0/ 6917]\n",
            "Avg loss: 2498.261401 \n",
            "\n",
            "Epoch 190\n",
            "-------------------------------\n",
            "loss: 2.21E+03  [    0/ 6917]\n",
            "Avg loss: 2483.380566 \n",
            "\n",
            "Epoch 191\n",
            "-------------------------------\n",
            "loss: 2.02E+03  [    0/ 6917]\n",
            "Avg loss: 2471.875928 \n",
            "\n",
            "Epoch 192\n",
            "-------------------------------\n",
            "loss: 2.77E+03  [    0/ 6917]\n",
            "Avg loss: 2553.922119 \n",
            "\n",
            "Epoch 193\n",
            "-------------------------------\n",
            "loss: 2.03E+03  [    0/ 6917]\n",
            "Avg loss: 2444.715186 \n",
            "\n",
            "Epoch 194\n",
            "-------------------------------\n",
            "loss: 2.56E+03  [    0/ 6917]\n",
            "Avg loss: 2378.806128 \n",
            "\n",
            "Epoch 195\n",
            "-------------------------------\n",
            "loss: 1.86E+03  [    0/ 6917]\n",
            "Avg loss: 2452.384375 \n",
            "\n",
            "Epoch 196\n",
            "-------------------------------\n",
            "loss: 1.87E+03  [    0/ 6917]\n",
            "Avg loss: 2430.709009 \n",
            "\n",
            "Epoch 197\n",
            "-------------------------------\n",
            "loss: 1.96E+03  [    0/ 6917]\n",
            "Avg loss: 2426.427393 \n",
            "\n",
            "Epoch 198\n",
            "-------------------------------\n",
            "loss: 2.26E+03  [    0/ 6917]\n",
            "Avg loss: 2341.838965 \n",
            "\n",
            "Epoch 199\n",
            "-------------------------------\n",
            "loss: 1.52E+03  [    0/ 6917]\n",
            "Avg loss: 2467.905518 \n",
            "\n",
            "Epoch 200\n",
            "-------------------------------\n",
            "loss: 2.33E+03  [    0/ 6917]\n",
            "Avg loss: 2341.289526 \n",
            "\n",
            "Epoch 201\n",
            "-------------------------------\n",
            "loss: 2.15E+03  [    0/ 6917]\n",
            "Avg loss: 2365.117236 \n",
            "\n",
            "Epoch 202\n",
            "-------------------------------\n",
            "loss: 2.01E+03  [    0/ 6917]\n",
            "Avg loss: 2420.476831 \n",
            "\n",
            "Epoch 203\n",
            "-------------------------------\n",
            "loss: 2.18E+03  [    0/ 6917]\n",
            "Avg loss: 2335.820581 \n",
            "\n",
            "Epoch 204\n",
            "-------------------------------\n",
            "loss: 1.55E+03  [    0/ 6917]\n",
            "Avg loss: 2391.711523 \n",
            "\n",
            "Epoch 205\n",
            "-------------------------------\n",
            "loss: 1.74E+03  [    0/ 6917]\n",
            "Avg loss: 2275.073828 \n",
            "\n",
            "Epoch 206\n",
            "-------------------------------\n",
            "loss: 1.95E+03  [    0/ 6917]\n",
            "Avg loss: 2372.648901 \n",
            "\n",
            "Epoch 207\n",
            "-------------------------------\n",
            "loss: 1.85E+03  [    0/ 6917]\n",
            "Avg loss: 2210.878394 \n",
            "\n",
            "Epoch 208\n",
            "-------------------------------\n",
            "loss: 1.60E+03  [    0/ 6917]\n",
            "Avg loss: 2314.240674 \n",
            "\n",
            "Epoch 209\n",
            "-------------------------------\n",
            "loss: 1.61E+03  [    0/ 6917]\n",
            "Avg loss: 2324.068506 \n",
            "\n",
            "Epoch 210\n",
            "-------------------------------\n",
            "loss: 1.90E+03  [    0/ 6917]\n",
            "Avg loss: 2404.368481 \n",
            "\n",
            "Epoch 211\n",
            "-------------------------------\n",
            "loss: 2.78E+03  [    0/ 6917]\n",
            "Avg loss: 2204.893555 \n",
            "\n",
            "Epoch 212\n",
            "-------------------------------\n",
            "loss: 2.12E+03  [    0/ 6917]\n",
            "Avg loss: 2278.671313 \n",
            "\n",
            "Epoch 213\n",
            "-------------------------------\n",
            "loss: 1.87E+03  [    0/ 6917]\n",
            "Avg loss: 2347.099976 \n",
            "\n",
            "Epoch 214\n",
            "-------------------------------\n",
            "loss: 1.81E+03  [    0/ 6917]\n",
            "Avg loss: 2230.925244 \n",
            "\n",
            "Epoch 215\n",
            "-------------------------------\n",
            "loss: 1.63E+03  [    0/ 6917]\n",
            "Avg loss: 2330.829663 \n",
            "\n",
            "Epoch 216\n",
            "-------------------------------\n",
            "loss: 1.88E+03  [    0/ 6917]\n",
            "Avg loss: 2240.279810 \n",
            "\n",
            "Epoch 217\n",
            "-------------------------------\n",
            "loss: 2.14E+03  [    0/ 6917]\n",
            "Avg loss: 2579.083398 \n",
            "\n",
            "Epoch 218\n",
            "-------------------------------\n",
            "loss: 2.15E+03  [    0/ 6917]\n",
            "Avg loss: 2236.971753 \n",
            "\n",
            "Epoch 219\n",
            "-------------------------------\n",
            "loss: 2.33E+03  [    0/ 6917]\n",
            "Avg loss: 2240.930957 \n",
            "\n",
            "Epoch 220\n",
            "-------------------------------\n",
            "loss: 1.94E+03  [    0/ 6917]\n",
            "Avg loss: 2221.426489 \n",
            "\n",
            "Epoch 221\n",
            "-------------------------------\n",
            "loss: 1.36E+03  [    0/ 6917]\n",
            "Avg loss: 2218.556152 \n",
            "\n",
            "Epoch 222\n",
            "-------------------------------\n",
            "loss: 1.54E+03  [    0/ 6917]\n",
            "Avg loss: 2087.867847 \n",
            "\n",
            "Epoch 223\n",
            "-------------------------------\n",
            "loss: 2.24E+03  [    0/ 6917]\n",
            "Avg loss: 2255.422119 \n",
            "\n",
            "Epoch 224\n",
            "-------------------------------\n",
            "loss: 2.36E+03  [    0/ 6917]\n",
            "Avg loss: 2424.500024 \n",
            "\n",
            "Epoch 225\n",
            "-------------------------------\n",
            "loss: 1.95E+03  [    0/ 6917]\n",
            "Avg loss: 2110.021021 \n",
            "\n",
            "Epoch 226\n",
            "-------------------------------\n",
            "loss: 2.24E+03  [    0/ 6917]\n",
            "Avg loss: 2118.245313 \n",
            "\n",
            "Epoch 227\n",
            "-------------------------------\n",
            "loss: 1.88E+03  [    0/ 6917]\n",
            "Avg loss: 2141.913184 \n",
            "\n",
            "Epoch 228\n",
            "-------------------------------\n",
            "loss: 1.46E+03  [    0/ 6917]\n",
            "Avg loss: 2148.417041 \n",
            "\n",
            "Epoch 229\n",
            "-------------------------------\n",
            "loss: 1.64E+03  [    0/ 6917]\n",
            "Avg loss: 2116.056006 \n",
            "\n",
            "Epoch 230\n",
            "-------------------------------\n",
            "loss: 1.60E+03  [    0/ 6917]\n",
            "Avg loss: 2133.721045 \n",
            "\n",
            "Epoch 231\n",
            "-------------------------------\n",
            "loss: 1.52E+03  [    0/ 6917]\n",
            "Avg loss: 2084.850757 \n",
            "\n",
            "Epoch 232\n",
            "-------------------------------\n",
            "loss: 2.30E+03  [    0/ 6917]\n",
            "Avg loss: 2121.496582 \n",
            "\n",
            "Epoch 233\n",
            "-------------------------------\n",
            "loss: 1.08E+03  [    0/ 6917]\n",
            "Avg loss: 2087.433545 \n",
            "\n",
            "Epoch 234\n",
            "-------------------------------\n",
            "loss: 1.70E+03  [    0/ 6917]\n",
            "Avg loss: 2088.400415 \n",
            "\n",
            "Epoch 235\n",
            "-------------------------------\n",
            "loss: 1.78E+03  [    0/ 6917]\n",
            "Avg loss: 1999.545264 \n",
            "\n",
            "Epoch 236\n",
            "-------------------------------\n",
            "loss: 1.90E+03  [    0/ 6917]\n",
            "Avg loss: 2019.753564 \n",
            "\n",
            "Epoch 237\n",
            "-------------------------------\n",
            "loss: 1.76E+03  [    0/ 6917]\n",
            "Avg loss: 2092.445532 \n",
            "\n",
            "Epoch 238\n",
            "-------------------------------\n",
            "loss: 1.81E+03  [    0/ 6917]\n",
            "Avg loss: 2002.628662 \n",
            "\n",
            "Epoch 239\n",
            "-------------------------------\n",
            "loss: 1.79E+03  [    0/ 6917]\n",
            "Avg loss: 1982.013623 \n",
            "\n",
            "Epoch 240\n",
            "-------------------------------\n",
            "loss: 1.88E+03  [    0/ 6917]\n",
            "Avg loss: 2012.229712 \n",
            "\n",
            "Epoch 241\n",
            "-------------------------------\n",
            "loss: 1.96E+03  [    0/ 6917]\n",
            "Avg loss: 2027.261938 \n",
            "\n",
            "Epoch 242\n",
            "-------------------------------\n",
            "loss: 1.41E+03  [    0/ 6917]\n",
            "Avg loss: 2065.423462 \n",
            "\n",
            "Epoch 243\n",
            "-------------------------------\n",
            "loss: 1.71E+03  [    0/ 6917]\n",
            "Avg loss: 2048.301074 \n",
            "\n",
            "Epoch 244\n",
            "-------------------------------\n",
            "loss: 1.42E+03  [    0/ 6917]\n",
            "Avg loss: 2323.973120 \n",
            "\n",
            "Epoch 245\n",
            "-------------------------------\n",
            "loss: 1.91E+03  [    0/ 6917]\n",
            "Avg loss: 2054.933179 \n",
            "\n",
            "Epoch 246\n",
            "-------------------------------\n",
            "loss: 1.49E+03  [    0/ 6917]\n",
            "Avg loss: 1987.699121 \n",
            "\n",
            "Epoch 247\n",
            "-------------------------------\n",
            "loss: 1.52E+03  [    0/ 6917]\n",
            "Avg loss: 1977.252466 \n",
            "\n",
            "Epoch 248\n",
            "-------------------------------\n",
            "loss: 1.59E+03  [    0/ 6917]\n",
            "Avg loss: 1929.605664 \n",
            "\n",
            "Epoch 249\n",
            "-------------------------------\n",
            "loss: 1.20E+03  [    0/ 6917]\n",
            "Avg loss: 1952.823267 \n",
            "\n",
            "Epoch 250\n",
            "-------------------------------\n",
            "loss: 1.36E+03  [    0/ 6917]\n",
            "Avg loss: 1892.583350 \n",
            "\n",
            "Epoch 251\n",
            "-------------------------------\n",
            "loss: 1.48E+03  [    0/ 6917]\n",
            "Avg loss: 2010.546655 \n",
            "\n",
            "Epoch 252\n",
            "-------------------------------\n",
            "loss: 1.52E+03  [    0/ 6917]\n",
            "Avg loss: 1948.215381 \n",
            "\n",
            "Epoch 253\n",
            "-------------------------------\n",
            "loss: 1.78E+03  [    0/ 6917]\n",
            "Avg loss: 1992.231055 \n",
            "\n",
            "Epoch 254\n",
            "-------------------------------\n",
            "loss: 1.78E+03  [    0/ 6917]\n",
            "Avg loss: 2011.867432 \n",
            "\n",
            "Epoch 255\n",
            "-------------------------------\n",
            "loss: 1.19E+03  [    0/ 6917]\n",
            "Avg loss: 1839.765259 \n",
            "\n",
            "Epoch 256\n",
            "-------------------------------\n",
            "loss: 1.36E+03  [    0/ 6917]\n",
            "Avg loss: 1997.708594 \n",
            "\n",
            "Epoch 257\n",
            "-------------------------------\n",
            "loss: 1.89E+03  [    0/ 6917]\n",
            "Avg loss: 1933.198779 \n",
            "\n",
            "Epoch 258\n",
            "-------------------------------\n",
            "loss: 1.54E+03  [    0/ 6917]\n",
            "Avg loss: 1907.486670 \n",
            "\n",
            "Epoch 259\n",
            "-------------------------------\n",
            "loss: 1.48E+03  [    0/ 6917]\n",
            "Avg loss: 1970.696655 \n",
            "\n",
            "Epoch 260\n",
            "-------------------------------\n",
            "loss: 1.65E+03  [    0/ 6917]\n",
            "Avg loss: 1886.181665 \n",
            "\n",
            "Epoch 261\n",
            "-------------------------------\n",
            "loss: 1.43E+03  [    0/ 6917]\n",
            "Avg loss: 1908.571655 \n",
            "\n",
            "Epoch 262\n",
            "-------------------------------\n",
            "loss: 1.69E+03  [    0/ 6917]\n",
            "Avg loss: 1929.655176 \n",
            "\n",
            "Epoch 263\n",
            "-------------------------------\n",
            "loss: 1.84E+03  [    0/ 6917]\n",
            "Avg loss: 1841.945703 \n",
            "\n",
            "Epoch 264\n",
            "-------------------------------\n",
            "loss: 1.40E+03  [    0/ 6917]\n",
            "Avg loss: 1867.969263 \n",
            "\n",
            "Epoch 265\n",
            "-------------------------------\n",
            "loss: 1.13E+03  [    0/ 6917]\n",
            "Avg loss: 1841.971484 \n",
            "\n",
            "Epoch 266\n",
            "-------------------------------\n",
            "loss: 1.67E+03  [    0/ 6917]\n",
            "Avg loss: 1866.130322 \n",
            "\n",
            "Epoch 267\n",
            "-------------------------------\n",
            "loss: 1.77E+03  [    0/ 6917]\n",
            "Avg loss: 1867.117383 \n",
            "\n",
            "Epoch 268\n",
            "-------------------------------\n",
            "loss: 1.53E+03  [    0/ 6917]\n",
            "Avg loss: 1798.373022 \n",
            "\n",
            "Epoch 269\n",
            "-------------------------------\n",
            "loss: 1.91E+03  [    0/ 6917]\n",
            "Avg loss: 1838.423535 \n",
            "\n",
            "Epoch 270\n",
            "-------------------------------\n",
            "loss: 1.24E+03  [    0/ 6917]\n",
            "Avg loss: 1809.013599 \n",
            "\n",
            "Epoch 271\n",
            "-------------------------------\n",
            "loss: 1.57E+03  [    0/ 6917]\n",
            "Avg loss: 1823.777368 \n",
            "\n",
            "Epoch 272\n",
            "-------------------------------\n",
            "loss: 1.53E+03  [    0/ 6917]\n",
            "Avg loss: 1783.919849 \n",
            "\n",
            "Epoch 273\n",
            "-------------------------------\n",
            "loss: 1.67E+03  [    0/ 6917]\n",
            "Avg loss: 1771.452881 \n",
            "\n",
            "Epoch 274\n",
            "-------------------------------\n",
            "loss: 1.26E+03  [    0/ 6917]\n",
            "Avg loss: 1715.293701 \n",
            "\n",
            "Epoch 275\n",
            "-------------------------------\n",
            "loss: 1.40E+03  [    0/ 6917]\n",
            "Avg loss: 1801.189673 \n",
            "\n",
            "Epoch 276\n",
            "-------------------------------\n",
            "loss: 1.38E+03  [    0/ 6917]\n",
            "Avg loss: 1770.292334 \n",
            "\n",
            "Epoch 277\n",
            "-------------------------------\n",
            "loss: 1.77E+03  [    0/ 6917]\n",
            "Avg loss: 1819.356982 \n",
            "\n",
            "Epoch 278\n",
            "-------------------------------\n",
            "loss: 1.50E+03  [    0/ 6917]\n",
            "Avg loss: 1796.435986 \n",
            "\n",
            "Epoch 279\n",
            "-------------------------------\n",
            "loss: 1.65E+03  [    0/ 6917]\n",
            "Avg loss: 1773.851147 \n",
            "\n",
            "Epoch 280\n",
            "-------------------------------\n",
            "loss: 1.33E+03  [    0/ 6917]\n",
            "Avg loss: 1887.538354 \n",
            "\n",
            "Epoch 281\n",
            "-------------------------------\n",
            "loss: 1.65E+03  [    0/ 6917]\n",
            "Avg loss: 1690.978979 \n",
            "\n",
            "Epoch 282\n",
            "-------------------------------\n",
            "loss: 1.47E+03  [    0/ 6917]\n",
            "Avg loss: 1733.632812 \n",
            "\n",
            "Epoch 283\n",
            "-------------------------------\n",
            "loss: 1.39E+03  [    0/ 6917]\n",
            "Avg loss: 1737.769116 \n",
            "\n",
            "Epoch 284\n",
            "-------------------------------\n",
            "loss: 1.39E+03  [    0/ 6917]\n",
            "Avg loss: 1706.675366 \n",
            "\n",
            "Epoch 285\n",
            "-------------------------------\n",
            "loss: 1.91E+03  [    0/ 6917]\n",
            "Avg loss: 1826.961719 \n",
            "\n",
            "Epoch 286\n",
            "-------------------------------\n",
            "loss: 1.30E+03  [    0/ 6917]\n",
            "Avg loss: 1807.193335 \n",
            "\n",
            "Epoch 287\n",
            "-------------------------------\n",
            "loss: 1.18E+03  [    0/ 6917]\n",
            "Avg loss: 1798.074048 \n",
            "\n",
            "Epoch 288\n",
            "-------------------------------\n",
            "loss: 1.66E+03  [    0/ 6917]\n",
            "Avg loss: 1690.405493 \n",
            "\n",
            "Epoch 289\n",
            "-------------------------------\n",
            "loss: 1.16E+03  [    0/ 6917]\n",
            "Avg loss: 1761.631494 \n",
            "\n",
            "Epoch 290\n",
            "-------------------------------\n",
            "loss: 1.31E+03  [    0/ 6917]\n",
            "Avg loss: 1694.515503 \n",
            "\n",
            "Epoch 291\n",
            "-------------------------------\n",
            "loss: 1.34E+03  [    0/ 6917]\n",
            "Avg loss: 1646.599146 \n",
            "\n",
            "Epoch 292\n",
            "-------------------------------\n",
            "loss: 1.59E+03  [    0/ 6917]\n",
            "Avg loss: 1692.928174 \n",
            "\n",
            "Epoch 293\n",
            "-------------------------------\n",
            "loss: 1.40E+03  [    0/ 6917]\n",
            "Avg loss: 1646.720654 \n",
            "\n",
            "Epoch 294\n",
            "-------------------------------\n",
            "loss: 1.47E+03  [    0/ 6917]\n",
            "Avg loss: 1694.247607 \n",
            "\n",
            "Epoch 295\n",
            "-------------------------------\n",
            "loss: 1.18E+03  [    0/ 6917]\n",
            "Avg loss: 1660.382324 \n",
            "\n",
            "Epoch 296\n",
            "-------------------------------\n",
            "loss: 1.53E+03  [    0/ 6917]\n",
            "Avg loss: 1592.357886 \n",
            "\n",
            "Epoch 297\n",
            "-------------------------------\n",
            "loss: 1.39E+03  [    0/ 6917]\n",
            "Avg loss: 1581.994092 \n",
            "\n",
            "Epoch 298\n",
            "-------------------------------\n",
            "loss: 1.15E+03  [    0/ 6917]\n",
            "Avg loss: 1624.608740 \n",
            "\n",
            "Epoch 299\n",
            "-------------------------------\n",
            "loss: 1.32E+03  [    0/ 6917]\n",
            "Avg loss: 1703.130640 \n",
            "\n",
            "Epoch 300\n",
            "-------------------------------\n",
            "loss: 1.59E+03  [    0/ 6917]\n",
            "Avg loss: 1578.644751 \n",
            "\n",
            "Epoch 301\n",
            "-------------------------------\n",
            "loss: 1.31E+03  [    0/ 6917]\n",
            "Avg loss: 1612.792896 \n",
            "\n",
            "Epoch 302\n",
            "-------------------------------\n",
            "loss: 1.16E+03  [    0/ 6917]\n",
            "Avg loss: 1625.735059 \n",
            "\n",
            "Epoch 303\n",
            "-------------------------------\n",
            "loss: 1.23E+03  [    0/ 6917]\n",
            "Avg loss: 1556.704077 \n",
            "\n",
            "Epoch 304\n",
            "-------------------------------\n",
            "loss: 1.23E+03  [    0/ 6917]\n",
            "Avg loss: 1650.625879 \n",
            "\n",
            "Epoch 305\n",
            "-------------------------------\n",
            "loss: 1.70E+03  [    0/ 6917]\n",
            "Avg loss: 1691.174707 \n",
            "\n",
            "Epoch 306\n",
            "-------------------------------\n",
            "loss: 1.33E+03  [    0/ 6917]\n",
            "Avg loss: 1706.792944 \n",
            "\n",
            "Epoch 307\n",
            "-------------------------------\n",
            "loss: 1.28E+03  [    0/ 6917]\n",
            "Avg loss: 1564.542480 \n",
            "\n",
            "Epoch 308\n",
            "-------------------------------\n",
            "loss: 1.43E+03  [    0/ 6917]\n",
            "Avg loss: 1546.388037 \n",
            "\n",
            "Epoch 309\n",
            "-------------------------------\n",
            "loss: 1.44E+03  [    0/ 6917]\n",
            "Avg loss: 1569.560522 \n",
            "\n",
            "Epoch 310\n",
            "-------------------------------\n",
            "loss: 9.09E+02  [    0/ 6917]\n",
            "Avg loss: 1645.166748 \n",
            "\n",
            "Epoch 311\n",
            "-------------------------------\n",
            "loss: 1.10E+03  [    0/ 6917]\n",
            "Avg loss: 1646.301514 \n",
            "\n",
            "Epoch 312\n",
            "-------------------------------\n",
            "loss: 1.09E+03  [    0/ 6917]\n",
            "Avg loss: 1512.425793 \n",
            "\n",
            "Epoch 313\n",
            "-------------------------------\n",
            "loss: 1.20E+03  [    0/ 6917]\n",
            "Avg loss: 1584.236133 \n",
            "\n",
            "Epoch 314\n",
            "-------------------------------\n",
            "loss: 1.21E+03  [    0/ 6917]\n",
            "Avg loss: 1540.784985 \n",
            "\n",
            "Epoch 315\n",
            "-------------------------------\n",
            "loss: 1.17E+03  [    0/ 6917]\n",
            "Avg loss: 1583.333447 \n",
            "\n",
            "Epoch 316\n",
            "-------------------------------\n",
            "loss: 1.15E+03  [    0/ 6917]\n",
            "Avg loss: 1544.999170 \n",
            "\n",
            "Epoch 317\n",
            "-------------------------------\n",
            "loss: 8.36E+02  [    0/ 6917]\n",
            "Avg loss: 1530.349316 \n",
            "\n",
            "Epoch 318\n",
            "-------------------------------\n",
            "loss: 1.24E+03  [    0/ 6917]\n",
            "Avg loss: 1539.894312 \n",
            "\n",
            "Epoch 319\n",
            "-------------------------------\n",
            "loss: 1.39E+03  [    0/ 6917]\n",
            "Avg loss: 1539.421411 \n",
            "\n",
            "Epoch 320\n",
            "-------------------------------\n",
            "loss: 1.32E+03  [    0/ 6917]\n",
            "Avg loss: 1578.787769 \n",
            "\n",
            "Epoch 321\n",
            "-------------------------------\n",
            "loss: 1.49E+03  [    0/ 6917]\n",
            "Avg loss: 1537.684180 \n",
            "\n",
            "Epoch 322\n",
            "-------------------------------\n",
            "loss: 1.34E+03  [    0/ 6917]\n",
            "Avg loss: 1533.864380 \n",
            "\n",
            "Epoch 323\n",
            "-------------------------------\n",
            "loss: 1.26E+03  [    0/ 6917]\n",
            "Avg loss: 1751.353931 \n",
            "\n",
            "Epoch 324\n",
            "-------------------------------\n",
            "loss: 1.28E+03  [    0/ 6917]\n",
            "Avg loss: 1476.567139 \n",
            "\n",
            "Epoch 325\n",
            "-------------------------------\n",
            "loss: 1.10E+03  [    0/ 6917]\n",
            "Avg loss: 1451.254053 \n",
            "\n",
            "Epoch 326\n",
            "-------------------------------\n",
            "loss: 1.37E+03  [    0/ 6917]\n",
            "Avg loss: 1496.048071 \n",
            "\n",
            "Epoch 327\n",
            "-------------------------------\n",
            "loss: 1.55E+03  [    0/ 6917]\n",
            "Avg loss: 1508.469995 \n",
            "\n",
            "Epoch 328\n",
            "-------------------------------\n",
            "loss: 1.41E+03  [    0/ 6917]\n",
            "Avg loss: 1472.735400 \n",
            "\n",
            "Epoch 329\n",
            "-------------------------------\n",
            "loss: 1.49E+03  [    0/ 6917]\n",
            "Avg loss: 1473.072241 \n",
            "\n",
            "Epoch 330\n",
            "-------------------------------\n",
            "loss: 1.18E+03  [    0/ 6917]\n",
            "Avg loss: 1613.313940 \n",
            "\n",
            "Epoch 331\n",
            "-------------------------------\n",
            "loss: 1.09E+03  [    0/ 6917]\n",
            "Avg loss: 1499.110913 \n",
            "\n",
            "Epoch 332\n",
            "-------------------------------\n",
            "loss: 1.05E+03  [    0/ 6917]\n",
            "Avg loss: 1498.877051 \n",
            "\n",
            "Epoch 333\n",
            "-------------------------------\n",
            "loss: 1.13E+03  [    0/ 6917]\n",
            "Avg loss: 1442.097266 \n",
            "\n",
            "Epoch 334\n",
            "-------------------------------\n",
            "loss: 1.03E+03  [    0/ 6917]\n",
            "Avg loss: 1420.679126 \n",
            "\n",
            "Epoch 335\n",
            "-------------------------------\n",
            "loss: 1.21E+03  [    0/ 6917]\n",
            "Avg loss: 1496.805493 \n",
            "\n",
            "Epoch 336\n",
            "-------------------------------\n",
            "loss: 1.33E+03  [    0/ 6917]\n",
            "Avg loss: 1462.034814 \n",
            "\n",
            "Epoch 337\n",
            "-------------------------------\n",
            "loss: 1.18E+03  [    0/ 6917]\n",
            "Avg loss: 1451.780762 \n",
            "\n",
            "Epoch 338\n",
            "-------------------------------\n",
            "loss: 1.13E+03  [    0/ 6917]\n",
            "Avg loss: 1421.778467 \n",
            "\n",
            "Epoch 339\n",
            "-------------------------------\n",
            "loss: 1.21E+03  [    0/ 6917]\n",
            "Avg loss: 1504.906641 \n",
            "\n",
            "Epoch 340\n",
            "-------------------------------\n",
            "loss: 1.20E+03  [    0/ 6917]\n",
            "Avg loss: 1438.547217 \n",
            "\n",
            "Epoch 341\n",
            "-------------------------------\n",
            "loss: 9.88E+02  [    0/ 6917]\n",
            "Avg loss: 1428.120532 \n",
            "\n",
            "Epoch 342\n",
            "-------------------------------\n",
            "loss: 1.35E+03  [    0/ 6917]\n",
            "Avg loss: 1408.980273 \n",
            "\n",
            "Epoch 343\n",
            "-------------------------------\n",
            "loss: 1.17E+03  [    0/ 6917]\n",
            "Avg loss: 1414.620996 \n",
            "\n",
            "Epoch 344\n",
            "-------------------------------\n",
            "loss: 1.43E+03  [    0/ 6917]\n",
            "Avg loss: 1449.445435 \n",
            "\n",
            "Epoch 345\n",
            "-------------------------------\n",
            "loss: 1.27E+03  [    0/ 6917]\n",
            "Avg loss: 1613.025635 \n",
            "\n",
            "Epoch 346\n",
            "-------------------------------\n",
            "loss: 1.81E+03  [    0/ 6917]\n",
            "Avg loss: 1407.375146 \n",
            "\n",
            "Epoch 347\n",
            "-------------------------------\n",
            "loss: 1.36E+03  [    0/ 6917]\n",
            "Avg loss: 1350.434985 \n",
            "\n",
            "Epoch 348\n",
            "-------------------------------\n",
            "loss: 8.05E+02  [    0/ 6917]\n",
            "Avg loss: 1344.351294 \n",
            "\n",
            "Epoch 349\n",
            "-------------------------------\n",
            "loss: 1.74E+03  [    0/ 6917]\n",
            "Avg loss: 1406.627783 \n",
            "\n",
            "Epoch 350\n",
            "-------------------------------\n",
            "loss: 1.00E+03  [    0/ 6917]\n",
            "Avg loss: 1348.573022 \n",
            "\n",
            "Epoch 351\n",
            "-------------------------------\n",
            "loss: 1.34E+03  [    0/ 6917]\n",
            "Avg loss: 1310.495935 \n",
            "\n",
            "Epoch 352\n",
            "-------------------------------\n",
            "loss: 1.35E+03  [    0/ 6917]\n",
            "Avg loss: 1363.729272 \n",
            "\n",
            "Epoch 353\n",
            "-------------------------------\n",
            "loss: 9.43E+02  [    0/ 6917]\n",
            "Avg loss: 1330.387720 \n",
            "\n",
            "Epoch 354\n",
            "-------------------------------\n",
            "loss: 8.34E+02  [    0/ 6917]\n",
            "Avg loss: 1405.878979 \n",
            "\n",
            "Epoch 355\n",
            "-------------------------------\n",
            "loss: 9.53E+02  [    0/ 6917]\n",
            "Avg loss: 1433.321655 \n",
            "\n",
            "Epoch 356\n",
            "-------------------------------\n",
            "loss: 1.21E+03  [    0/ 6917]\n",
            "Avg loss: 1480.325195 \n",
            "\n",
            "Epoch 357\n",
            "-------------------------------\n",
            "loss: 1.26E+03  [    0/ 6917]\n",
            "Avg loss: 1432.781714 \n",
            "\n",
            "Epoch 358\n",
            "-------------------------------\n",
            "loss: 1.22E+03  [    0/ 6917]\n",
            "Avg loss: 1344.556104 \n",
            "\n",
            "Epoch 359\n",
            "-------------------------------\n",
            "loss: 1.07E+03  [    0/ 6917]\n",
            "Avg loss: 1307.961060 \n",
            "\n",
            "Epoch 360\n",
            "-------------------------------\n",
            "loss: 1.08E+03  [    0/ 6917]\n",
            "Avg loss: 1353.065356 \n",
            "\n",
            "Epoch 361\n",
            "-------------------------------\n",
            "loss: 1.35E+03  [    0/ 6917]\n",
            "Avg loss: 1314.173218 \n",
            "\n",
            "Epoch 362\n",
            "-------------------------------\n",
            "loss: 1.59E+03  [    0/ 6917]\n",
            "Avg loss: 1358.117310 \n",
            "\n",
            "Epoch 363\n",
            "-------------------------------\n",
            "loss: 8.55E+02  [    0/ 6917]\n",
            "Avg loss: 1370.284741 \n",
            "\n",
            "Epoch 364\n",
            "-------------------------------\n",
            "loss: 9.77E+02  [    0/ 6917]\n",
            "Avg loss: 1329.962305 \n",
            "\n",
            "Epoch 365\n",
            "-------------------------------\n",
            "loss: 7.55E+02  [    0/ 6917]\n",
            "Avg loss: 1438.164624 \n",
            "\n",
            "Epoch 366\n",
            "-------------------------------\n",
            "loss: 9.37E+02  [    0/ 6917]\n",
            "Avg loss: 1376.214148 \n",
            "\n",
            "Epoch 367\n",
            "-------------------------------\n",
            "loss: 1.25E+03  [    0/ 6917]\n",
            "Avg loss: 1285.851514 \n",
            "\n",
            "Epoch 368\n",
            "-------------------------------\n",
            "loss: 1.32E+03  [    0/ 6917]\n",
            "Avg loss: 1320.378906 \n",
            "\n",
            "Epoch 369\n",
            "-------------------------------\n",
            "loss: 9.85E+02  [    0/ 6917]\n",
            "Avg loss: 1321.048169 \n",
            "\n",
            "Epoch 370\n",
            "-------------------------------\n",
            "loss: 1.01E+03  [    0/ 6917]\n",
            "Avg loss: 1398.030737 \n",
            "\n",
            "Epoch 371\n",
            "-------------------------------\n",
            "loss: 1.52E+03  [    0/ 6917]\n",
            "Avg loss: 1291.687939 \n",
            "\n",
            "Epoch 372\n",
            "-------------------------------\n",
            "loss: 1.17E+03  [    0/ 6917]\n",
            "Avg loss: 1542.114575 \n",
            "\n",
            "Epoch 373\n",
            "-------------------------------\n",
            "loss: 1.43E+03  [    0/ 6917]\n",
            "Avg loss: 1319.840698 \n",
            "\n",
            "Epoch 374\n",
            "-------------------------------\n",
            "loss: 9.76E+02  [    0/ 6917]\n",
            "Avg loss: 1319.044604 \n",
            "\n",
            "Epoch 375\n",
            "-------------------------------\n",
            "loss: 1.11E+03  [    0/ 6917]\n",
            "Avg loss: 1320.163220 \n",
            "\n",
            "Epoch 376\n",
            "-------------------------------\n",
            "loss: 8.10E+02  [    0/ 6917]\n",
            "Avg loss: 1289.398450 \n",
            "\n",
            "Epoch 377\n",
            "-------------------------------\n",
            "loss: 1.01E+03  [    0/ 6917]\n",
            "Avg loss: 1292.367578 \n",
            "\n",
            "Epoch 378\n",
            "-------------------------------\n",
            "loss: 1.09E+03  [    0/ 6917]\n",
            "Avg loss: 1298.454175 \n",
            "\n",
            "Epoch 379\n",
            "-------------------------------\n",
            "loss: 8.94E+02  [    0/ 6917]\n",
            "Avg loss: 1306.032043 \n",
            "\n",
            "Epoch 380\n",
            "-------------------------------\n",
            "loss: 8.51E+02  [    0/ 6917]\n",
            "Avg loss: 1313.518604 \n",
            "\n",
            "Epoch 381\n",
            "-------------------------------\n",
            "loss: 9.70E+02  [    0/ 6917]\n",
            "Avg loss: 1274.776538 \n",
            "\n",
            "Epoch 382\n",
            "-------------------------------\n",
            "loss: 1.11E+03  [    0/ 6917]\n",
            "Avg loss: 1266.281824 \n",
            "\n",
            "Epoch 383\n",
            "-------------------------------\n",
            "loss: 9.09E+02  [    0/ 6917]\n",
            "Avg loss: 1229.230432 \n",
            "\n",
            "Epoch 384\n",
            "-------------------------------\n",
            "loss: 1.10E+03  [    0/ 6917]\n",
            "Avg loss: 1329.904407 \n",
            "\n",
            "Epoch 385\n",
            "-------------------------------\n",
            "loss: 9.94E+02  [    0/ 6917]\n",
            "Avg loss: 1301.314795 \n",
            "\n",
            "Epoch 386\n",
            "-------------------------------\n",
            "loss: 8.26E+02  [    0/ 6917]\n",
            "Avg loss: 1306.355237 \n",
            "\n",
            "Epoch 387\n",
            "-------------------------------\n",
            "loss: 1.28E+03  [    0/ 6917]\n",
            "Avg loss: 1259.584741 \n",
            "\n",
            "Epoch 388\n",
            "-------------------------------\n",
            "loss: 7.32E+02  [    0/ 6917]\n",
            "Avg loss: 1229.064661 \n",
            "\n",
            "Epoch 389\n",
            "-------------------------------\n",
            "loss: 1.19E+03  [    0/ 6917]\n",
            "Avg loss: 1302.052637 \n",
            "\n",
            "Epoch 390\n",
            "-------------------------------\n",
            "loss: 8.12E+02  [    0/ 6917]\n",
            "Avg loss: 1394.867017 \n",
            "\n",
            "Epoch 391\n",
            "-------------------------------\n",
            "loss: 1.13E+03  [    0/ 6917]\n",
            "Avg loss: 1287.977258 \n",
            "\n",
            "Epoch 392\n",
            "-------------------------------\n",
            "loss: 1.00E+03  [    0/ 6917]\n",
            "Avg loss: 1294.142651 \n",
            "\n",
            "Epoch 393\n",
            "-------------------------------\n",
            "loss: 9.83E+02  [    0/ 6917]\n",
            "Avg loss: 1246.420703 \n",
            "\n",
            "Epoch 394\n",
            "-------------------------------\n",
            "loss: 7.96E+02  [    0/ 6917]\n",
            "Avg loss: 1233.275037 \n",
            "\n",
            "Epoch 395\n",
            "-------------------------------\n",
            "loss: 8.09E+02  [    0/ 6917]\n",
            "Avg loss: 1217.456995 \n",
            "\n",
            "Epoch 396\n",
            "-------------------------------\n",
            "loss: 1.04E+03  [    0/ 6917]\n",
            "Avg loss: 1180.543713 \n",
            "\n",
            "Epoch 397\n",
            "-------------------------------\n",
            "loss: 1.21E+03  [    0/ 6917]\n",
            "Avg loss: 1207.763184 \n",
            "\n",
            "Epoch 398\n",
            "-------------------------------\n",
            "loss: 7.35E+02  [    0/ 6917]\n",
            "Avg loss: 1195.034094 \n",
            "\n",
            "Epoch 399\n",
            "-------------------------------\n",
            "loss: 8.87E+02  [    0/ 6917]\n",
            "Avg loss: 1251.490454 \n",
            "\n",
            "Epoch 400\n",
            "-------------------------------\n",
            "loss: 8.06E+02  [    0/ 6917]\n",
            "Avg loss: 1227.836279 \n",
            "\n",
            "Epoch 401\n",
            "-------------------------------\n",
            "loss: 1.11E+03  [    0/ 6917]\n",
            "Avg loss: 1166.482800 \n",
            "\n",
            "Epoch 402\n",
            "-------------------------------\n",
            "loss: 9.89E+02  [    0/ 6917]\n",
            "Avg loss: 1205.978796 \n",
            "\n",
            "Epoch 403\n",
            "-------------------------------\n",
            "loss: 9.80E+02  [    0/ 6917]\n",
            "Avg loss: 1233.765698 \n",
            "\n",
            "Epoch 404\n",
            "-------------------------------\n",
            "loss: 1.10E+03  [    0/ 6917]\n",
            "Avg loss: 1326.677148 \n",
            "\n",
            "Epoch 405\n",
            "-------------------------------\n",
            "loss: 1.06E+03  [    0/ 6917]\n",
            "Avg loss: 1344.024927 \n",
            "\n",
            "Epoch 406\n",
            "-------------------------------\n",
            "loss: 1.13E+03  [    0/ 6917]\n",
            "Avg loss: 1273.358911 \n",
            "\n",
            "Epoch 407\n",
            "-------------------------------\n",
            "loss: 1.12E+03  [    0/ 6917]\n",
            "Avg loss: 1318.879651 \n",
            "\n",
            "Epoch 408\n",
            "-------------------------------\n",
            "loss: 1.19E+03  [    0/ 6917]\n",
            "Avg loss: 1210.062085 \n",
            "\n",
            "Epoch 409\n",
            "-------------------------------\n",
            "loss: 1.16E+03  [    0/ 6917]\n",
            "Avg loss: 1207.414490 \n",
            "\n",
            "Epoch 410\n",
            "-------------------------------\n",
            "loss: 1.05E+03  [    0/ 6917]\n",
            "Avg loss: 1158.457080 \n",
            "\n",
            "Epoch 411\n",
            "-------------------------------\n",
            "loss: 1.14E+03  [    0/ 6917]\n",
            "Avg loss: 1239.026953 \n",
            "\n",
            "Epoch 412\n",
            "-------------------------------\n",
            "loss: 1.00E+03  [    0/ 6917]\n",
            "Avg loss: 1212.783154 \n",
            "\n",
            "Epoch 413\n",
            "-------------------------------\n",
            "loss: 8.67E+02  [    0/ 6917]\n",
            "Avg loss: 1199.838855 \n",
            "\n",
            "Epoch 414\n",
            "-------------------------------\n",
            "loss: 9.58E+02  [    0/ 6917]\n",
            "Avg loss: 1179.909875 \n",
            "\n",
            "Epoch 415\n",
            "-------------------------------\n",
            "loss: 8.63E+02  [    0/ 6917]\n",
            "Avg loss: 1240.650415 \n",
            "\n",
            "Epoch 416\n",
            "-------------------------------\n",
            "loss: 8.48E+02  [    0/ 6917]\n",
            "Avg loss: 1289.584900 \n",
            "\n",
            "Epoch 417\n",
            "-------------------------------\n",
            "loss: 1.20E+03  [    0/ 6917]\n",
            "Avg loss: 1141.717920 \n",
            "\n",
            "Epoch 418\n",
            "-------------------------------\n",
            "loss: 9.02E+02  [    0/ 6917]\n",
            "Avg loss: 1102.872278 \n",
            "\n",
            "Epoch 419\n",
            "-------------------------------\n",
            "loss: 1.28E+03  [    0/ 6917]\n",
            "Avg loss: 1146.920142 \n",
            "\n",
            "Epoch 420\n",
            "-------------------------------\n",
            "loss: 8.79E+02  [    0/ 6917]\n",
            "Avg loss: 1171.777173 \n",
            "\n",
            "Epoch 421\n",
            "-------------------------------\n",
            "loss: 8.95E+02  [    0/ 6917]\n",
            "Avg loss: 1157.523376 \n",
            "\n",
            "Epoch 422\n",
            "-------------------------------\n",
            "loss: 7.64E+02  [    0/ 6917]\n",
            "Avg loss: 1178.578723 \n",
            "\n",
            "Epoch 423\n",
            "-------------------------------\n",
            "loss: 1.05E+03  [    0/ 6917]\n",
            "Avg loss: 1152.677893 \n",
            "\n",
            "Epoch 424\n",
            "-------------------------------\n",
            "loss: 9.53E+02  [    0/ 6917]\n",
            "Avg loss: 1100.189844 \n",
            "\n",
            "Epoch 425\n",
            "-------------------------------\n",
            "loss: 8.85E+02  [    0/ 6917]\n",
            "Avg loss: 1184.415356 \n",
            "\n",
            "Epoch 426\n",
            "-------------------------------\n",
            "loss: 8.92E+02  [    0/ 6917]\n",
            "Avg loss: 1121.706116 \n",
            "\n",
            "Epoch 427\n",
            "-------------------------------\n",
            "loss: 7.82E+02  [    0/ 6917]\n",
            "Avg loss: 1171.315771 \n",
            "\n",
            "Epoch 428\n",
            "-------------------------------\n",
            "loss: 1.03E+03  [    0/ 6917]\n",
            "Avg loss: 1206.019165 \n",
            "\n",
            "Epoch 429\n",
            "-------------------------------\n",
            "loss: 6.55E+02  [    0/ 6917]\n",
            "Avg loss: 1066.776453 \n",
            "\n",
            "Epoch 430\n",
            "-------------------------------\n",
            "loss: 6.49E+02  [    0/ 6917]\n",
            "Avg loss: 1073.187634 \n",
            "\n",
            "Epoch 431\n",
            "-------------------------------\n",
            "loss: 7.86E+02  [    0/ 6917]\n",
            "Avg loss: 1098.443323 \n",
            "\n",
            "Epoch 432\n",
            "-------------------------------\n",
            "loss: 1.06E+03  [    0/ 6917]\n",
            "Avg loss: 1134.533313 \n",
            "\n",
            "Epoch 433\n",
            "-------------------------------\n",
            "loss: 9.24E+02  [    0/ 6917]\n",
            "Avg loss: 1106.362146 \n",
            "\n",
            "Epoch 434\n",
            "-------------------------------\n",
            "loss: 9.82E+02  [    0/ 6917]\n",
            "Avg loss: 1102.928296 \n",
            "\n",
            "Epoch 435\n",
            "-------------------------------\n",
            "loss: 7.90E+02  [    0/ 6917]\n",
            "Avg loss: 1063.325366 \n",
            "\n",
            "Epoch 436\n",
            "-------------------------------\n",
            "loss: 7.68E+02  [    0/ 6917]\n",
            "Avg loss: 1109.391370 \n",
            "\n",
            "Epoch 437\n",
            "-------------------------------\n",
            "loss: 9.96E+02  [    0/ 6917]\n",
            "Avg loss: 1128.642297 \n",
            "\n",
            "Epoch 438\n",
            "-------------------------------\n",
            "loss: 1.03E+03  [    0/ 6917]\n",
            "Avg loss: 1073.006409 \n",
            "\n",
            "Epoch 439\n",
            "-------------------------------\n",
            "loss: 8.40E+02  [    0/ 6917]\n",
            "Avg loss: 1215.626880 \n",
            "\n",
            "Epoch 440\n",
            "-------------------------------\n",
            "loss: 9.51E+02  [    0/ 6917]\n",
            "Avg loss: 1098.312598 \n",
            "\n",
            "Epoch 441\n",
            "-------------------------------\n",
            "loss: 7.48E+02  [    0/ 6917]\n",
            "Avg loss: 1083.359338 \n",
            "\n",
            "Epoch 442\n",
            "-------------------------------\n",
            "loss: 9.88E+02  [    0/ 6917]\n",
            "Avg loss: 1048.560620 \n",
            "\n",
            "Epoch 443\n",
            "-------------------------------\n",
            "loss: 7.52E+02  [    0/ 6917]\n",
            "Avg loss: 1102.559937 \n",
            "\n",
            "Epoch 444\n",
            "-------------------------------\n",
            "loss: 8.03E+02  [    0/ 6917]\n",
            "Avg loss: 1079.190820 \n",
            "\n",
            "Epoch 445\n",
            "-------------------------------\n",
            "loss: 9.33E+02  [    0/ 6917]\n",
            "Avg loss: 1090.394739 \n",
            "\n",
            "Epoch 446\n",
            "-------------------------------\n",
            "loss: 7.67E+02  [    0/ 6917]\n",
            "Avg loss: 1092.735864 \n",
            "\n",
            "Epoch 447\n",
            "-------------------------------\n",
            "loss: 8.58E+02  [    0/ 6917]\n",
            "Avg loss: 1018.371436 \n",
            "\n",
            "Epoch 448\n",
            "-------------------------------\n",
            "loss: 6.12E+02  [    0/ 6917]\n",
            "Avg loss: 1045.837500 \n",
            "\n",
            "Epoch 449\n",
            "-------------------------------\n",
            "loss: 5.48E+02  [    0/ 6917]\n",
            "Avg loss: 1092.939075 \n",
            "\n",
            "Epoch 450\n",
            "-------------------------------\n",
            "loss: 7.75E+02  [    0/ 6917]\n",
            "Avg loss: 1020.563330 \n",
            "\n",
            "Epoch 451\n",
            "-------------------------------\n",
            "loss: 7.93E+02  [    0/ 6917]\n",
            "Avg loss: 1027.019397 \n",
            "\n",
            "Epoch 452\n",
            "-------------------------------\n",
            "loss: 1.08E+03  [    0/ 6917]\n",
            "Avg loss: 1055.085852 \n",
            "\n",
            "Epoch 453\n",
            "-------------------------------\n",
            "loss: 9.44E+02  [    0/ 6917]\n",
            "Avg loss: 1039.525562 \n",
            "\n",
            "Epoch 454\n",
            "-------------------------------\n",
            "loss: 5.83E+02  [    0/ 6917]\n",
            "Avg loss: 1036.561279 \n",
            "\n",
            "Epoch 455\n",
            "-------------------------------\n",
            "loss: 9.59E+02  [    0/ 6917]\n",
            "Avg loss: 1082.429590 \n",
            "\n",
            "Epoch 456\n",
            "-------------------------------\n",
            "loss: 1.48E+03  [    0/ 6917]\n",
            "Avg loss: 1061.064844 \n",
            "\n",
            "Epoch 457\n",
            "-------------------------------\n",
            "loss: 9.03E+02  [    0/ 6917]\n",
            "Avg loss: 1026.870264 \n",
            "\n",
            "Epoch 458\n",
            "-------------------------------\n",
            "loss: 8.57E+02  [    0/ 6917]\n",
            "Avg loss: 1028.342700 \n",
            "\n",
            "Epoch 459\n",
            "-------------------------------\n",
            "loss: 8.45E+02  [    0/ 6917]\n",
            "Avg loss: 1020.174573 \n",
            "\n",
            "Epoch 460\n",
            "-------------------------------\n",
            "loss: 8.01E+02  [    0/ 6917]\n",
            "Avg loss: 1076.368750 \n",
            "\n",
            "Epoch 461\n",
            "-------------------------------\n",
            "loss: 9.87E+02  [    0/ 6917]\n",
            "Avg loss: 1034.751965 \n",
            "\n",
            "Epoch 462\n",
            "-------------------------------\n",
            "loss: 7.56E+02  [    0/ 6917]\n",
            "Avg loss: 1039.025830 \n",
            "\n",
            "Epoch 463\n",
            "-------------------------------\n",
            "loss: 8.54E+02  [    0/ 6917]\n",
            "Avg loss: 1029.657788 \n",
            "\n",
            "Epoch 464\n",
            "-------------------------------\n",
            "loss: 9.42E+02  [    0/ 6917]\n",
            "Avg loss: 1006.305420 \n",
            "\n",
            "Epoch 465\n",
            "-------------------------------\n",
            "loss: 8.17E+02  [    0/ 6917]\n",
            "Avg loss: 1009.720166 \n",
            "\n",
            "Epoch 466\n",
            "-------------------------------\n",
            "loss: 7.32E+02  [    0/ 6917]\n",
            "Avg loss: 1031.846497 \n",
            "\n",
            "Epoch 467\n",
            "-------------------------------\n",
            "loss: 9.42E+02  [    0/ 6917]\n",
            "Avg loss: 1054.841663 \n",
            "\n",
            "Epoch 468\n",
            "-------------------------------\n",
            "loss: 8.45E+02  [    0/ 6917]\n",
            "Avg loss: 1021.762695 \n",
            "\n",
            "Epoch 469\n",
            "-------------------------------\n",
            "loss: 6.79E+02  [    0/ 6917]\n",
            "Avg loss: 1026.562451 \n",
            "\n",
            "Epoch 470\n",
            "-------------------------------\n",
            "loss: 9.80E+02  [    0/ 6917]\n",
            "Avg loss: 990.482581 \n",
            "\n",
            "Epoch 471\n",
            "-------------------------------\n",
            "loss: 1.22E+03  [    0/ 6917]\n",
            "Avg loss: 981.897949 \n",
            "\n",
            "Epoch 472\n",
            "-------------------------------\n",
            "loss: 8.59E+02  [    0/ 6917]\n",
            "Avg loss: 971.450159 \n",
            "\n",
            "Epoch 473\n",
            "-------------------------------\n",
            "loss: 8.07E+02  [    0/ 6917]\n",
            "Avg loss: 973.017480 \n",
            "\n",
            "Epoch 474\n",
            "-------------------------------\n",
            "loss: 6.16E+02  [    0/ 6917]\n",
            "Avg loss: 986.681189 \n",
            "\n",
            "Epoch 475\n",
            "-------------------------------\n",
            "loss: 7.26E+02  [    0/ 6917]\n",
            "Avg loss: 969.548730 \n",
            "\n",
            "Epoch 476\n",
            "-------------------------------\n",
            "loss: 7.45E+02  [    0/ 6917]\n",
            "Avg loss: 1142.015076 \n",
            "\n",
            "Epoch 477\n",
            "-------------------------------\n",
            "loss: 8.23E+02  [    0/ 6917]\n",
            "Avg loss: 1059.805151 \n",
            "\n",
            "Epoch 478\n",
            "-------------------------------\n",
            "loss: 7.69E+02  [    0/ 6917]\n",
            "Avg loss: 966.515320 \n",
            "\n",
            "Epoch 479\n",
            "-------------------------------\n",
            "loss: 1.11E+03  [    0/ 6917]\n",
            "Avg loss: 969.183557 \n",
            "\n",
            "Epoch 480\n",
            "-------------------------------\n",
            "loss: 7.08E+02  [    0/ 6917]\n",
            "Avg loss: 967.572925 \n",
            "\n",
            "Epoch 481\n",
            "-------------------------------\n",
            "loss: 9.97E+02  [    0/ 6917]\n",
            "Avg loss: 988.493066 \n",
            "\n",
            "Epoch 482\n",
            "-------------------------------\n",
            "loss: 7.29E+02  [    0/ 6917]\n",
            "Avg loss: 986.029224 \n",
            "\n",
            "Epoch 483\n",
            "-------------------------------\n",
            "loss: 9.05E+02  [    0/ 6917]\n",
            "Avg loss: 986.107727 \n",
            "\n",
            "Epoch 484\n",
            "-------------------------------\n",
            "loss: 7.06E+02  [    0/ 6917]\n",
            "Avg loss: 1023.635205 \n",
            "\n",
            "Epoch 485\n",
            "-------------------------------\n",
            "loss: 1.14E+03  [    0/ 6917]\n",
            "Avg loss: 947.285669 \n",
            "\n",
            "Epoch 486\n",
            "-------------------------------\n",
            "loss: 7.66E+02  [    0/ 6917]\n",
            "Avg loss: 921.387695 \n",
            "\n",
            "Epoch 487\n",
            "-------------------------------\n",
            "loss: 7.49E+02  [    0/ 6917]\n",
            "Avg loss: 978.580310 \n",
            "\n",
            "Epoch 488\n",
            "-------------------------------\n",
            "loss: 6.82E+02  [    0/ 6917]\n",
            "Avg loss: 986.888037 \n",
            "\n",
            "Epoch 489\n",
            "-------------------------------\n",
            "loss: 6.88E+02  [    0/ 6917]\n",
            "Avg loss: 924.948755 \n",
            "\n",
            "Epoch 490\n",
            "-------------------------------\n",
            "loss: 6.16E+02  [    0/ 6917]\n",
            "Avg loss: 953.063562 \n",
            "\n",
            "Epoch 491\n",
            "-------------------------------\n",
            "loss: 7.23E+02  [    0/ 6917]\n",
            "Avg loss: 944.913684 \n",
            "\n",
            "Epoch 492\n",
            "-------------------------------\n",
            "loss: 9.18E+02  [    0/ 6917]\n",
            "Avg loss: 1003.128369 \n",
            "\n",
            "Epoch 493\n",
            "-------------------------------\n",
            "loss: 8.48E+02  [    0/ 6917]\n",
            "Avg loss: 1001.121216 \n",
            "\n",
            "Epoch 494\n",
            "-------------------------------\n",
            "loss: 7.61E+02  [    0/ 6917]\n",
            "Avg loss: 961.234253 \n",
            "\n",
            "Epoch 495\n",
            "-------------------------------\n",
            "loss: 8.73E+02  [    0/ 6917]\n",
            "Avg loss: 1041.575879 \n",
            "\n",
            "Epoch 496\n",
            "-------------------------------\n",
            "loss: 8.37E+02  [    0/ 6917]\n",
            "Avg loss: 1002.468994 \n",
            "\n",
            "Epoch 497\n",
            "-------------------------------\n",
            "loss: 9.04E+02  [    0/ 6917]\n",
            "Avg loss: 965.919214 \n",
            "\n",
            "Epoch 498\n",
            "-------------------------------\n",
            "loss: 7.05E+02  [    0/ 6917]\n",
            "Avg loss: 1038.176074 \n",
            "\n",
            "Epoch 499\n",
            "-------------------------------\n",
            "loss: 7.75E+02  [    0/ 6917]\n",
            "Avg loss: 962.411743 \n",
            "\n",
            "Epoch 500\n",
            "-------------------------------\n",
            "loss: 7.98E+02  [    0/ 6917]\n",
            "Avg loss: 986.922546 \n",
            "\n",
            "Epoch 501\n",
            "-------------------------------\n",
            "loss: 8.88E+02  [    0/ 6917]\n",
            "Avg loss: 984.247070 \n",
            "\n",
            "Epoch 502\n",
            "-------------------------------\n",
            "loss: 7.43E+02  [    0/ 6917]\n",
            "Avg loss: 927.415076 \n",
            "\n",
            "Epoch 503\n",
            "-------------------------------\n",
            "loss: 7.87E+02  [    0/ 6917]\n",
            "Avg loss: 980.439490 \n",
            "\n",
            "Epoch 504\n",
            "-------------------------------\n",
            "loss: 7.62E+02  [    0/ 6917]\n",
            "Avg loss: 1013.527283 \n",
            "\n",
            "Epoch 505\n",
            "-------------------------------\n",
            "loss: 7.59E+02  [    0/ 6917]\n",
            "Avg loss: 891.875769 \n",
            "\n",
            "Epoch 506\n",
            "-------------------------------\n",
            "loss: 6.70E+02  [    0/ 6917]\n",
            "Avg loss: 909.316583 \n",
            "\n",
            "Epoch 507\n",
            "-------------------------------\n",
            "loss: 7.95E+02  [    0/ 6917]\n",
            "Avg loss: 951.682153 \n",
            "\n",
            "Epoch 508\n",
            "-------------------------------\n",
            "loss: 7.82E+02  [    0/ 6917]\n",
            "Avg loss: 971.132141 \n",
            "\n",
            "Epoch 509\n",
            "-------------------------------\n",
            "loss: 6.44E+02  [    0/ 6917]\n",
            "Avg loss: 912.661646 \n",
            "\n",
            "Epoch 510\n",
            "-------------------------------\n",
            "loss: 5.80E+02  [    0/ 6917]\n",
            "Avg loss: 896.707568 \n",
            "\n",
            "Epoch 511\n",
            "-------------------------------\n",
            "loss: 7.08E+02  [    0/ 6917]\n",
            "Avg loss: 979.332471 \n",
            "\n",
            "Epoch 512\n",
            "-------------------------------\n",
            "loss: 7.53E+02  [    0/ 6917]\n",
            "Avg loss: 947.315869 \n",
            "\n",
            "Epoch 513\n",
            "-------------------------------\n",
            "loss: 5.64E+02  [    0/ 6917]\n",
            "Avg loss: 912.351721 \n",
            "\n",
            "Epoch 514\n",
            "-------------------------------\n",
            "loss: 7.60E+02  [    0/ 6917]\n",
            "Avg loss: 875.263647 \n",
            "\n",
            "Epoch 515\n",
            "-------------------------------\n",
            "loss: 8.40E+02  [    0/ 6917]\n",
            "Avg loss: 854.775525 \n",
            "\n",
            "Epoch 516\n",
            "-------------------------------\n",
            "loss: 5.62E+02  [    0/ 6917]\n",
            "Avg loss: 854.258606 \n",
            "\n",
            "Epoch 517\n",
            "-------------------------------\n",
            "loss: 7.78E+02  [    0/ 6917]\n",
            "Avg loss: 903.883264 \n",
            "\n",
            "Epoch 518\n",
            "-------------------------------\n",
            "loss: 7.82E+02  [    0/ 6917]\n",
            "Avg loss: 913.384265 \n",
            "\n",
            "Epoch 519\n",
            "-------------------------------\n",
            "loss: 6.32E+02  [    0/ 6917]\n",
            "Avg loss: 868.985022 \n",
            "\n",
            "Epoch 520\n",
            "-------------------------------\n",
            "loss: 7.09E+02  [    0/ 6917]\n",
            "Avg loss: 896.299475 \n",
            "\n",
            "Epoch 521\n",
            "-------------------------------\n",
            "loss: 7.19E+02  [    0/ 6917]\n",
            "Avg loss: 944.073767 \n",
            "\n",
            "Epoch 522\n",
            "-------------------------------\n",
            "loss: 6.88E+02  [    0/ 6917]\n",
            "Avg loss: 892.876794 \n",
            "\n",
            "Epoch 523\n",
            "-------------------------------\n",
            "loss: 7.25E+02  [    0/ 6917]\n",
            "Avg loss: 904.606433 \n",
            "\n",
            "Epoch 524\n",
            "-------------------------------\n",
            "loss: 6.74E+02  [    0/ 6917]\n",
            "Avg loss: 960.359741 \n",
            "\n",
            "Epoch 525\n",
            "-------------------------------\n",
            "loss: 6.76E+02  [    0/ 6917]\n",
            "Avg loss: 1210.142078 \n",
            "\n",
            "Epoch 526\n",
            "-------------------------------\n",
            "loss: 7.44E+02  [    0/ 6917]\n",
            "Avg loss: 921.365479 \n",
            "\n",
            "Epoch 527\n",
            "-------------------------------\n",
            "loss: 6.39E+02  [    0/ 6917]\n",
            "Avg loss: 873.572021 \n",
            "\n",
            "Epoch 528\n",
            "-------------------------------\n",
            "loss: 7.34E+02  [    0/ 6917]\n",
            "Avg loss: 880.212427 \n",
            "\n",
            "Epoch 529\n",
            "-------------------------------\n",
            "loss: 6.47E+02  [    0/ 6917]\n",
            "Avg loss: 863.337390 \n",
            "\n",
            "Epoch 530\n",
            "-------------------------------\n",
            "loss: 7.02E+02  [    0/ 6917]\n",
            "Avg loss: 847.942383 \n",
            "\n",
            "Epoch 531\n",
            "-------------------------------\n",
            "loss: 6.57E+02  [    0/ 6917]\n",
            "Avg loss: 862.846899 \n",
            "\n",
            "Epoch 532\n",
            "-------------------------------\n",
            "loss: 5.78E+02  [    0/ 6917]\n",
            "Avg loss: 861.997449 \n",
            "\n",
            "Epoch 533\n",
            "-------------------------------\n",
            "loss: 6.72E+02  [    0/ 6917]\n",
            "Avg loss: 944.913989 \n",
            "\n",
            "Epoch 534\n",
            "-------------------------------\n",
            "loss: 7.61E+02  [    0/ 6917]\n",
            "Avg loss: 878.938062 \n",
            "\n",
            "Epoch 535\n",
            "-------------------------------\n",
            "loss: 5.87E+02  [    0/ 6917]\n",
            "Avg loss: 928.258264 \n",
            "\n",
            "Epoch 536\n",
            "-------------------------------\n",
            "loss: 6.98E+02  [    0/ 6917]\n",
            "Avg loss: 876.680676 \n",
            "\n",
            "Epoch 537\n",
            "-------------------------------\n",
            "loss: 7.14E+02  [    0/ 6917]\n",
            "Avg loss: 932.844336 \n",
            "\n",
            "Epoch 538\n",
            "-------------------------------\n",
            "loss: 6.51E+02  [    0/ 6917]\n",
            "Avg loss: 835.594336 \n",
            "\n",
            "Epoch 539\n",
            "-------------------------------\n",
            "loss: 5.50E+02  [    0/ 6917]\n",
            "Avg loss: 846.932239 \n",
            "\n",
            "Epoch 540\n",
            "-------------------------------\n",
            "loss: 7.19E+02  [    0/ 6917]\n",
            "Avg loss: 865.239258 \n",
            "\n",
            "Epoch 541\n",
            "-------------------------------\n",
            "loss: 5.97E+02  [    0/ 6917]\n",
            "Avg loss: 837.967126 \n",
            "\n",
            "Epoch 542\n",
            "-------------------------------\n",
            "loss: 7.97E+02  [    0/ 6917]\n",
            "Avg loss: 926.115454 \n",
            "\n",
            "Epoch 543\n",
            "-------------------------------\n",
            "loss: 7.51E+02  [    0/ 6917]\n",
            "Avg loss: 886.868274 \n",
            "\n",
            "Epoch 544\n",
            "-------------------------------\n",
            "loss: 6.25E+02  [    0/ 6917]\n",
            "Avg loss: 924.062048 \n",
            "\n",
            "Epoch 545\n",
            "-------------------------------\n",
            "loss: 7.58E+02  [    0/ 6917]\n",
            "Avg loss: 875.601294 \n",
            "\n",
            "Epoch 546\n",
            "-------------------------------\n",
            "loss: 4.78E+02  [    0/ 6917]\n",
            "Avg loss: 828.856421 \n",
            "\n",
            "Epoch 547\n",
            "-------------------------------\n",
            "loss: 6.46E+02  [    0/ 6917]\n",
            "Avg loss: 849.917273 \n",
            "\n",
            "Epoch 548\n",
            "-------------------------------\n",
            "loss: 7.47E+02  [    0/ 6917]\n",
            "Avg loss: 840.376099 \n",
            "\n",
            "Epoch 549\n",
            "-------------------------------\n",
            "loss: 6.49E+02  [    0/ 6917]\n",
            "Avg loss: 982.610242 \n",
            "\n",
            "Epoch 550\n",
            "-------------------------------\n",
            "loss: 1.12E+03  [    0/ 6917]\n",
            "Avg loss: 838.472534 \n",
            "\n",
            "Epoch 551\n",
            "-------------------------------\n",
            "loss: 5.74E+02  [    0/ 6917]\n",
            "Avg loss: 785.688672 \n",
            "\n",
            "Epoch 552\n",
            "-------------------------------\n",
            "loss: 5.78E+02  [    0/ 6917]\n",
            "Avg loss: 849.154370 \n",
            "\n",
            "Epoch 553\n",
            "-------------------------------\n",
            "loss: 7.90E+02  [    0/ 6917]\n",
            "Avg loss: 919.377771 \n",
            "\n",
            "Epoch 554\n",
            "-------------------------------\n",
            "loss: 5.69E+02  [    0/ 6917]\n",
            "Avg loss: 850.264502 \n",
            "\n",
            "Epoch 555\n",
            "-------------------------------\n",
            "loss: 6.08E+02  [    0/ 6917]\n",
            "Avg loss: 816.104065 \n",
            "\n",
            "Epoch 556\n",
            "-------------------------------\n",
            "loss: 6.74E+02  [    0/ 6917]\n",
            "Avg loss: 800.839758 \n",
            "\n",
            "Epoch 557\n",
            "-------------------------------\n",
            "loss: 6.75E+02  [    0/ 6917]\n",
            "Avg loss: 827.109448 \n",
            "\n",
            "Epoch 558\n",
            "-------------------------------\n",
            "loss: 6.03E+02  [    0/ 6917]\n",
            "Avg loss: 854.855103 \n",
            "\n",
            "Epoch 559\n",
            "-------------------------------\n",
            "loss: 6.15E+02  [    0/ 6917]\n",
            "Avg loss: 840.385901 \n",
            "\n",
            "Epoch 560\n",
            "-------------------------------\n",
            "loss: 6.41E+02  [    0/ 6917]\n",
            "Avg loss: 819.425049 \n",
            "\n",
            "Epoch 561\n",
            "-------------------------------\n",
            "loss: 5.69E+02  [    0/ 6917]\n",
            "Avg loss: 858.506128 \n",
            "\n",
            "Epoch 562\n",
            "-------------------------------\n",
            "loss: 8.94E+02  [    0/ 6917]\n",
            "Avg loss: 809.645947 \n",
            "\n",
            "Epoch 563\n",
            "-------------------------------\n",
            "loss: 8.12E+02  [    0/ 6917]\n",
            "Avg loss: 820.695471 \n",
            "\n",
            "Epoch 564\n",
            "-------------------------------\n",
            "loss: 7.02E+02  [    0/ 6917]\n",
            "Avg loss: 802.966248 \n",
            "\n",
            "Epoch 565\n",
            "-------------------------------\n",
            "loss: 4.63E+02  [    0/ 6917]\n",
            "Avg loss: 806.430652 \n",
            "\n",
            "Epoch 566\n",
            "-------------------------------\n",
            "loss: 6.54E+02  [    0/ 6917]\n",
            "Avg loss: 798.446423 \n",
            "\n",
            "Epoch 567\n",
            "-------------------------------\n",
            "loss: 4.95E+02  [    0/ 6917]\n",
            "Avg loss: 883.006030 \n",
            "\n",
            "Epoch 568\n",
            "-------------------------------\n",
            "loss: 7.76E+02  [    0/ 6917]\n",
            "Avg loss: 780.670728 \n",
            "\n",
            "Epoch 569\n",
            "-------------------------------\n",
            "loss: 4.56E+02  [    0/ 6917]\n",
            "Avg loss: 830.757996 \n",
            "\n",
            "Epoch 570\n",
            "-------------------------------\n",
            "loss: 6.37E+02  [    0/ 6917]\n",
            "Avg loss: 858.732910 \n",
            "\n",
            "Epoch 571\n",
            "-------------------------------\n",
            "loss: 6.11E+02  [    0/ 6917]\n",
            "Avg loss: 806.702393 \n",
            "\n",
            "Epoch 572\n",
            "-------------------------------\n",
            "loss: 6.57E+02  [    0/ 6917]\n",
            "Avg loss: 832.196814 \n",
            "\n",
            "Epoch 573\n",
            "-------------------------------\n",
            "loss: 7.60E+02  [    0/ 6917]\n",
            "Avg loss: 804.875781 \n",
            "\n",
            "Epoch 574\n",
            "-------------------------------\n",
            "loss: 4.29E+02  [    0/ 6917]\n",
            "Avg loss: 943.790930 \n",
            "\n",
            "Epoch 575\n",
            "-------------------------------\n",
            "loss: 7.69E+02  [    0/ 6917]\n",
            "Avg loss: 787.136890 \n",
            "\n",
            "Epoch 576\n",
            "-------------------------------\n",
            "loss: 7.93E+02  [    0/ 6917]\n",
            "Avg loss: 803.489221 \n",
            "\n",
            "Epoch 577\n",
            "-------------------------------\n",
            "loss: 5.13E+02  [    0/ 6917]\n",
            "Avg loss: 803.050928 \n",
            "\n",
            "Epoch 578\n",
            "-------------------------------\n",
            "loss: 8.93E+02  [    0/ 6917]\n",
            "Avg loss: 782.258008 \n",
            "\n",
            "Epoch 579\n",
            "-------------------------------\n",
            "loss: 5.25E+02  [    0/ 6917]\n",
            "Avg loss: 814.308582 \n",
            "\n",
            "Epoch 580\n",
            "-------------------------------\n",
            "loss: 7.35E+02  [    0/ 6917]\n",
            "Avg loss: 899.672107 \n",
            "\n",
            "Epoch 581\n",
            "-------------------------------\n",
            "loss: 5.32E+02  [    0/ 6917]\n",
            "Avg loss: 974.475879 \n",
            "\n",
            "Epoch 582\n",
            "-------------------------------\n",
            "loss: 6.09E+02  [    0/ 6917]\n",
            "Avg loss: 972.941431 \n",
            "\n",
            "Epoch 583\n",
            "-------------------------------\n",
            "loss: 4.95E+02  [    0/ 6917]\n",
            "Avg loss: 941.114685 \n",
            "\n",
            "Epoch 584\n",
            "-------------------------------\n",
            "loss: 6.64E+02  [    0/ 6917]\n",
            "Avg loss: 844.227124 \n",
            "\n",
            "Epoch 585\n",
            "-------------------------------\n",
            "loss: 6.99E+02  [    0/ 6917]\n",
            "Avg loss: 788.465527 \n",
            "\n",
            "Epoch 586\n",
            "-------------------------------\n",
            "loss: 6.17E+02  [    0/ 6917]\n",
            "Avg loss: 814.181030 \n",
            "\n",
            "Epoch 587\n",
            "-------------------------------\n",
            "loss: 7.66E+02  [    0/ 6917]\n",
            "Avg loss: 851.864465 \n",
            "\n",
            "Epoch 588\n",
            "-------------------------------\n",
            "loss: 5.29E+02  [    0/ 6917]\n",
            "Avg loss: 796.585730 \n",
            "\n",
            "Epoch 589\n",
            "-------------------------------\n",
            "loss: 6.91E+02  [    0/ 6917]\n",
            "Avg loss: 886.984705 \n",
            "\n",
            "Epoch 590\n",
            "-------------------------------\n",
            "loss: 7.68E+02  [    0/ 6917]\n",
            "Avg loss: 777.631860 \n",
            "\n",
            "Epoch 591\n",
            "-------------------------------\n",
            "loss: 6.42E+02  [    0/ 6917]\n",
            "Avg loss: 878.557629 \n",
            "\n",
            "Epoch 592\n",
            "-------------------------------\n",
            "loss: 6.66E+02  [    0/ 6917]\n",
            "Avg loss: 756.499866 \n",
            "\n",
            "Epoch 593\n",
            "-------------------------------\n",
            "loss: 4.85E+02  [    0/ 6917]\n",
            "Avg loss: 764.698511 \n",
            "\n",
            "Epoch 594\n",
            "-------------------------------\n",
            "loss: 7.20E+02  [    0/ 6917]\n",
            "Avg loss: 733.332556 \n",
            "\n",
            "Epoch 595\n",
            "-------------------------------\n",
            "loss: 4.97E+02  [    0/ 6917]\n",
            "Avg loss: 772.685510 \n",
            "\n",
            "Epoch 596\n",
            "-------------------------------\n",
            "loss: 4.91E+02  [    0/ 6917]\n",
            "Avg loss: 780.326135 \n",
            "\n",
            "Epoch 597\n",
            "-------------------------------\n",
            "loss: 7.82E+02  [    0/ 6917]\n",
            "Avg loss: 779.575830 \n",
            "\n",
            "Epoch 598\n",
            "-------------------------------\n",
            "loss: 6.46E+02  [    0/ 6917]\n",
            "Avg loss: 752.016846 \n",
            "\n",
            "Epoch 599\n",
            "-------------------------------\n",
            "loss: 4.04E+02  [    0/ 6917]\n",
            "Avg loss: 760.889050 \n",
            "\n",
            "Epoch 600\n",
            "-------------------------------\n",
            "loss: 4.56E+02  [    0/ 6917]\n",
            "Avg loss: 901.918945 \n",
            "\n",
            "Epoch 601\n",
            "-------------------------------\n",
            "loss: 8.56E+02  [    0/ 6917]\n",
            "Avg loss: 803.120276 \n",
            "\n",
            "Epoch 602\n",
            "-------------------------------\n",
            "loss: 5.22E+02  [    0/ 6917]\n",
            "Avg loss: 747.426636 \n",
            "\n",
            "Epoch 603\n",
            "-------------------------------\n",
            "loss: 6.66E+02  [    0/ 6917]\n",
            "Avg loss: 747.816284 \n",
            "\n",
            "Epoch 604\n",
            "-------------------------------\n",
            "loss: 6.60E+02  [    0/ 6917]\n",
            "Avg loss: 724.582727 \n",
            "\n",
            "Epoch 605\n",
            "-------------------------------\n",
            "loss: 4.12E+02  [    0/ 6917]\n",
            "Avg loss: 748.394409 \n",
            "\n",
            "Epoch 606\n",
            "-------------------------------\n",
            "loss: 6.66E+02  [    0/ 6917]\n",
            "Avg loss: 811.268274 \n",
            "\n",
            "Epoch 607\n",
            "-------------------------------\n",
            "loss: 6.78E+02  [    0/ 6917]\n",
            "Avg loss: 796.428943 \n",
            "\n",
            "Epoch 608\n",
            "-------------------------------\n",
            "loss: 6.95E+02  [    0/ 6917]\n",
            "Avg loss: 756.616357 \n",
            "\n",
            "Epoch 609\n",
            "-------------------------------\n",
            "loss: 6.48E+02  [    0/ 6917]\n",
            "Avg loss: 788.712061 \n",
            "\n",
            "Epoch 610\n",
            "-------------------------------\n",
            "loss: 5.53E+02  [    0/ 6917]\n",
            "Avg loss: 761.165527 \n",
            "\n",
            "Epoch 611\n",
            "-------------------------------\n",
            "loss: 6.78E+02  [    0/ 6917]\n",
            "Avg loss: 746.367859 \n",
            "\n",
            "Epoch 612\n",
            "-------------------------------\n",
            "loss: 6.99E+02  [    0/ 6917]\n",
            "Avg loss: 869.382910 \n",
            "\n",
            "Epoch 613\n",
            "-------------------------------\n",
            "loss: 6.22E+02  [    0/ 6917]\n",
            "Avg loss: 822.343420 \n",
            "\n",
            "Epoch 614\n",
            "-------------------------------\n",
            "loss: 7.00E+02  [    0/ 6917]\n",
            "Avg loss: 750.304016 \n",
            "\n",
            "Epoch 615\n",
            "-------------------------------\n",
            "loss: 5.94E+02  [    0/ 6917]\n",
            "Avg loss: 723.979395 \n",
            "\n",
            "Epoch 616\n",
            "-------------------------------\n",
            "loss: 5.48E+02  [    0/ 6917]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-aa0b4a3b7392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-148-1f4be06ccc54>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Definition of loss function and optimizer\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),weight_decay=10)\n",
        "\n",
        "# Training loop\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "797dae55",
      "metadata": {
        "id": "797dae55"
      },
      "outputs": [],
      "source": [
        "i = 250\n",
        "model(torch.from_numpy(X_CV[i]).float().to(device)), y_CV[i]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 250\n",
        "model(torch.from_numpy(X_train[i]).float().to(device)), y_train[i]"
      ],
      "metadata": {
        "id": "Wm8YgjfTAggA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "fe40b682-b416-4aa8-eae7-210c8ac10c21"
      },
      "id": "Wm8YgjfTAggA",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-111e2ce50103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wJJq-6ZBTg3Z"
      },
      "id": "wJJq-6ZBTg3Z",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}